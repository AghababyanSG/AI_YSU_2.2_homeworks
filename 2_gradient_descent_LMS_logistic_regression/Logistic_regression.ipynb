{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1PWbGOvZZg4shD-Y1m0ULHfIeHrzV3VL7","authorship_tag":"ABX9TyNDHKJiKNUQmBNFOggQ5raE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"FZTJMt-pc7hc","executionInfo":{"status":"ok","timestamp":1708583439129,"user_tz":-240,"elapsed":314,"user":{"displayName":"Ստեփան Սարգսյան","userId":"17563089324629164814"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["The optimization problem of logistic regression is a binary classification problem. Given a set of features $x$, we want to predict whether a sample belongs to one of two classes, which we'll call \"positive\" and \"negative\", i.e. $y=1$ or $0$. The loss of the problem is the sigmoid cross entropy loss, which has the following form\n","$$L(θ) = -\\sum_{i} \\big[y_i log(\\hat{y}_i(θ) + (1 - y_i) log(1 - \\hat{y}_i(θ)\\big]$$\n","where in our case $\\hat{y} = \\sigma (x^T\\theta)$ and $\\sigma$ is the sigmoid function, $z = x^T\\theta$ is called logit"],"metadata":{"id":"5fR9OSTbdLA4"}},{"cell_type":"markdown","source":["#Creating a Dataset\n","\n","To create a dataset, we'll use scikit-learn's make_classification function, which generates a random n-class classification problem. We'll use two classes (n_classes=2) and generate 1000 samples with 10 features (n_features=10)."],"metadata":{"id":"h3RXay8SPevK"}},{"cell_type":"code","source":["from sklearn.datasets import make_classification\n","import numpy as np\n","\n","X, y = make_classification(n_samples=100, n_features=10, n_classes=2, class_sep=0.3, random_state=42)\n","# Add intercept column to X (for bias)\n","X = np.hstack((np.ones((X.shape[0], 1)), X))\n","# make y matrix\n","y = y[:, np.newaxis]\n","print(X.shape, y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ym-bHRO-PmZw","executionInfo":{"status":"ok","timestamp":1708583460080,"user_tz":-240,"elapsed":278,"user":{"displayName":"Ստեփան Սարգսյան","userId":"17563089324629164814"}},"outputId":"7f8204b4-71f4-432b-efac-2babd38f6106"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["(100, 11) (100, 1)\n"]}]},{"cell_type":"markdown","source":["Next, we define a gradient descent function, i.e. apply the gradients and update the parameter values iteratively"],"metadata":{"id":"ROKKGUuQMOGI"}},{"cell_type":"code","source":["import numpy as np\n","\n","def sigmoid(z):\n","    return 1 / (1 + np.exp(-z))\n","\n","def sigmoid_cross_entropy(y, y_pred):\n","    '''\n","    y: labels\n","    y_pred: probabilistic output in [0,1]\n","    '''\n","    assert y.shape == y_pred.shape, \"label and prediction shapes should be equal\"\n","    L = -(np.mean(y*np.log(y_pred) + (1-y)*np.log(1-y_pred)))\n","    return L\n","\n","def logistic_regression(X, y, learning_rate=0.01, num_iterations=1000):\n","    m, n = X.shape\n","    theta = np.zeros((n, 1))\n","    for i in range(num_iterations):\n","        z = np.dot(X, theta)\n","        y_pred = sigmoid(z)\n","        gradient = np.dot(X.T, (y_pred - y)) / m\n","        theta = theta - learning_rate * gradient\n","        loss = sigmoid_cross_entropy(y, y_pred)\n","        print(f\"Step {i}, Loss: {loss}\")\n","    return theta\n"],"metadata":{"id":"N81wgVlcQ7Mp","executionInfo":{"status":"ok","timestamp":1708583408240,"user_tz":-240,"elapsed":4,"user":{"displayName":"Ստեփան Սարգսյան","userId":"17563089324629164814"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["Now let's evaluate the model"],"metadata":{"id":"imOAFHALasjL"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","theta = logistic_regression(X_train, y_train, num_iterations = 1000)\n","y_pred = sigmoid(np.dot(X_test, theta)) > 0.5\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JXxNEAzqSM5P","executionInfo":{"status":"ok","timestamp":1708583464725,"user_tz":-240,"elapsed":838,"user":{"displayName":"Ստեփան Սարգսյան","userId":"17563089324629164814"}},"outputId":"cc6938de-ff0e-411c-fb1b-77bc64cb2374"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 0, Loss: 0.6931471805599453\n","Step 1, Loss: 0.692322107826435\n","Step 2, Loss: 0.6915025000368387\n","Step 3, Loss: 0.6906883095760641\n","Step 4, Loss: 0.6898794891918815\n","Step 5, Loss: 0.6890759919945875\n","Step 6, Loss: 0.6882777714565933\n","Step 7, Loss: 0.6874847814119394\n","Step 8, Loss: 0.6866969760557391\n","Step 9, Loss: 0.6859143099435524\n","Step 10, Loss: 0.6851367379906931\n","Step 11, Loss: 0.684364215471468\n","Step 12, Loss: 0.6835966980183562\n","Step 13, Loss: 0.6828341416211237\n","Step 14, Loss: 0.6820765026258794\n","Step 15, Loss: 0.6813237377340735\n","Step 16, Loss: 0.6805758040014388\n","Step 17, Loss: 0.6798326588368785\n","Step 18, Loss: 0.6790942600013012\n","Step 19, Loss: 0.6783605656064056\n","Step 20, Loss: 0.6776315341134146\n","Step 21, Loss: 0.6769071243317641\n","Step 22, Loss: 0.6761872954177452\n","Step 23, Loss: 0.6754720068731019\n","Step 24, Loss: 0.6747612185435872\n","Step 25, Loss: 0.6740548906174775\n","Step 26, Loss: 0.6733529836240489\n","Step 27, Loss: 0.6726554584320148\n","Step 28, Loss: 0.6719622762479276\n","Step 29, Loss: 0.6712733986145454\n","Step 30, Loss: 0.6705887874091656\n","Step 31, Loss: 0.6699084048419273\n","Step 32, Loss: 0.6692322134540811\n","Step 33, Loss: 0.6685601761162321\n","Step 34, Loss: 0.6678922560265541\n","Step 35, Loss: 0.6672284167089765\n","Step 36, Loss: 0.6665686220113474\n","Step 37, Loss: 0.6659128361035715\n","Step 38, Loss: 0.6652610234757269\n","Step 39, Loss: 0.6646131489361574\n","Step 40, Loss: 0.6639691776095475\n","Step 41, Loss: 0.6633290749349763\n","Step 42, Loss: 0.6626928066639544\n","Step 43, Loss: 0.6620603388584418\n","Step 44, Loss: 0.6614316378888528\n","Step 45, Loss: 0.6608066704320427\n","Step 46, Loss: 0.6601854034692828\n","Step 47, Loss: 0.6595678042842218\n","Step 48, Loss: 0.6589538404608352\n","Step 49, Loss: 0.658343479881363\n","Step 50, Loss: 0.6577366907242382\n","Step 51, Loss: 0.6571334414620058\n","Step 52, Loss: 0.6565337008592322\n","Step 53, Loss: 0.65593743797041\n","Step 54, Loss: 0.6553446221378518\n","Step 55, Loss: 0.6547552229895819\n","Step 56, Loss: 0.6541692104372208\n","Step 57, Loss: 0.6535865546738655\n","Step 58, Loss: 0.6530072261719669\n","Step 59, Loss: 0.6524311956812034\n","Step 60, Loss: 0.6518584342263518\n","Step 61, Loss: 0.6512889131051581\n","Step 62, Loss: 0.6507226038862062\n","Step 63, Loss: 0.6501594784067862\n","Step 64, Loss: 0.6495995087707628\n","Step 65, Loss: 0.6490426673464462\n","Step 66, Loss: 0.6484889267644618\n","Step 67, Loss: 0.6479382599156238\n","Step 68, Loss: 0.6473906399488103\n","Step 69, Loss: 0.6468460402688423\n","Step 70, Loss: 0.646304434534365\n","Step 71, Loss: 0.645765796655734\n","Step 72, Loss: 0.6452301007929058\n","Step 73, Loss: 0.6446973213533325\n","Step 74, Loss: 0.644167432989863\n","Step 75, Loss: 0.643640410598649\n","Step 76, Loss: 0.6431162293170571\n","Step 77, Loss: 0.6425948645215882\n","Step 78, Loss: 0.6420762918258035\n","Step 79, Loss: 0.6415604870782569\n","Step 80, Loss: 0.641047426360436\n","Step 81, Loss: 0.6405370859847112\n","Step 82, Loss: 0.6400294424922913\n","Step 83, Loss: 0.6395244726511911\n","Step 84, Loss: 0.6390221534542025\n","Step 85, Loss: 0.6385224621168808\n","Step 86, Loss: 0.6380253760755359\n","Step 87, Loss: 0.6375308729852345\n","Step 88, Loss: 0.6370389307178133\n","Step 89, Loss: 0.6365495273599004\n","Step 90, Loss: 0.6360626412109486\n","Step 91, Loss: 0.6355782507812784\n","Step 92, Loss: 0.6350963347901313\n","Step 93, Loss: 0.6346168721637364\n","Step 94, Loss: 0.634139842033384\n","Step 95, Loss: 0.633665223733515\n","Step 96, Loss: 0.6331929967998184\n","Step 97, Loss: 0.6327231409673422\n","Step 98, Loss: 0.6322556361686145\n","Step 99, Loss: 0.631790462531779\n","Step 100, Loss: 0.6313276003787394\n","Step 101, Loss: 0.6308670302233181\n","Step 102, Loss: 0.6304087327694268\n","Step 103, Loss: 0.6299526889092479\n","Step 104, Loss: 0.6294988797214314\n","Step 105, Loss: 0.6290472864693009\n","Step 106, Loss: 0.6285978905990734\n","Step 107, Loss: 0.6281506737380942\n","Step 108, Loss: 0.6277056176930806\n","Step 109, Loss: 0.6272627044483808\n","Step 110, Loss: 0.6268219161642452\n","Step 111, Loss: 0.6263832351751109\n","Step 112, Loss: 0.6259466439878976\n","Step 113, Loss: 0.6255121252803194\n","Step 114, Loss: 0.6250796618992066\n","Step 115, Loss: 0.6246492368588422\n","Step 116, Loss: 0.6242208333393117\n","Step 117, Loss: 0.6237944346848643\n","Step 118, Loss: 0.6233700244022897\n","Step 119, Loss: 0.622947586159306\n","Step 120, Loss: 0.6225271037829609\n","Step 121, Loss: 0.622108561258048\n","Step 122, Loss: 0.6216919427255331\n","Step 123, Loss: 0.6212772324809962\n","Step 124, Loss: 0.6208644149730859\n","Step 125, Loss: 0.620453474801986\n","Step 126, Loss: 0.6200443967178961\n","Step 127, Loss: 0.6196371656195251\n","Step 128, Loss: 0.6192317665525974\n","Step 129, Loss: 0.6188281847083725\n","Step 130, Loss: 0.6184264054221773\n","Step 131, Loss: 0.6180264141719514\n","Step 132, Loss: 0.6176281965768047\n","Step 133, Loss: 0.6172317383955898\n","Step 134, Loss: 0.6168370255254845\n","Step 135, Loss: 0.6164440440005887\n","Step 136, Loss: 0.6160527799905345\n","Step 137, Loss: 0.6156632197991072\n","Step 138, Loss: 0.6152753498628807\n","Step 139, Loss: 0.6148891567498633\n","Step 140, Loss: 0.6145046271581596\n","Step 141, Loss: 0.6141217479146404\n","Step 142, Loss: 0.6137405059736285\n","Step 143, Loss: 0.6133608884155951\n","Step 144, Loss: 0.612982882445869\n","Step 145, Loss: 0.6126064753933578\n","Step 146, Loss: 0.6122316547092812\n","Step 147, Loss: 0.6118584079659171\n","Step 148, Loss: 0.6114867228553581\n","Step 149, Loss: 0.6111165871882819\n","Step 150, Loss: 0.610747988892732\n","Step 151, Loss: 0.6103809160129107\n","Step 152, Loss: 0.6100153567079845\n","Step 153, Loss: 0.6096512992508997\n","Step 154, Loss: 0.6092887320272108\n","Step 155, Loss: 0.6089276435339203\n","Step 156, Loss: 0.6085680223783285\n","Step 157, Loss: 0.6082098572768972\n","Step 158, Loss: 0.6078531370541217\n","Step 159, Loss: 0.6074978506414166\n","Step 160, Loss: 0.6071439870760105\n","Step 161, Loss: 0.6067915354998537\n","Step 162, Loss: 0.6064404851585351\n","Step 163, Loss: 0.6060908254002111\n","Step 164, Loss: 0.6057425456745456\n","Step 165, Loss: 0.6053956355316582\n","Step 166, Loss: 0.6050500846210866\n","Step 167, Loss: 0.6047058826907566\n","Step 168, Loss: 0.6043630195859647\n","Step 169, Loss: 0.6040214852483687\n","Step 170, Loss: 0.6036812697149914\n","Step 171, Loss: 0.6033423631172317\n","Step 172, Loss: 0.6030047556798881\n","Step 173, Loss: 0.6026684377201905\n","Step 174, Loss: 0.6023333996468434\n","Step 175, Loss: 0.6019996319590776\n","Step 176, Loss: 0.601667125245713\n","Step 177, Loss: 0.6013358701842297\n","Step 178, Loss: 0.6010058575398501\n","Step 179, Loss: 0.6006770781646296\n","Step 180, Loss: 0.6003495229965565\n","Step 181, Loss: 0.600023183058663\n","Step 182, Loss: 0.5996980494581431\n","Step 183, Loss: 0.5993741133854812\n","Step 184, Loss: 0.5990513661135897\n","Step 185, Loss: 0.5987297989969551\n","Step 186, Loss: 0.5984094034707936\n","Step 187, Loss: 0.5980901710502151\n","Step 188, Loss: 0.5977720933293963\n","Step 189, Loss: 0.597455161980762\n","Step 190, Loss: 0.5971393687541762\n","Step 191, Loss: 0.5968247054761402\n","Step 192, Loss: 0.5965111640490003\n","Step 193, Loss: 0.5961987364501636\n","Step 194, Loss: 0.5958874147313219\n","Step 195, Loss: 0.5955771910176834\n","Step 196, Loss: 0.5952680575072138\n","Step 197, Loss: 0.5949600064698847\n","Step 198, Loss: 0.5946530302469294\n","Step 199, Loss: 0.5943471212501079\n","Step 200, Loss: 0.5940422719609788\n","Step 201, Loss: 0.5937384749301788\n","Step 202, Loss: 0.5934357227767116\n","Step 203, Loss: 0.5931340081872415\n","Step 204, Loss: 0.592833323915397\n","Step 205, Loss: 0.592533662781081\n","Step 206, Loss: 0.5922350176697883\n","Step 207, Loss: 0.5919373815319302\n","Step 208, Loss: 0.5916407473821671\n","Step 209, Loss: 0.5913451082987473\n","Step 210, Loss: 0.5910504574228537\n","Step 211, Loss: 0.5907567879579566\n","Step 212, Loss: 0.5904640931691751\n","Step 213, Loss: 0.5901723663826431\n","Step 214, Loss: 0.5898816009848843\n","Step 215, Loss: 0.5895917904221919\n","Step 216, Loss: 0.5893029282000167\n","Step 217, Loss: 0.5890150078823614\n","Step 218, Loss: 0.5887280230911797\n","Step 219, Loss: 0.588441967505785\n","Step 220, Loss: 0.5881568348622624\n","Step 221, Loss: 0.5878726189528894\n","Step 222, Loss: 0.5875893136255608\n","Step 223, Loss: 0.5873069127832216\n","Step 224, Loss: 0.5870254103833054\n","Step 225, Loss: 0.5867448004371777\n","Step 226, Loss: 0.5864650770095876\n","Step 227, Loss: 0.5861862342181228\n","Step 228, Loss: 0.5859082662326724\n","Step 229, Loss: 0.5856311672748953\n","Step 230, Loss: 0.5853549316176923\n","Step 231, Loss: 0.5850795535846871\n","Step 232, Loss: 0.584805027549711\n","Step 233, Loss: 0.5845313479362926\n","Step 234, Loss: 0.5842585092171546\n","Step 235, Loss: 0.5839865059137155\n","Step 236, Loss: 0.5837153325955959\n","Step 237, Loss: 0.5834449838801317\n","Step 238, Loss: 0.5831754544318899\n","Step 239, Loss: 0.5829067389621934\n","Step 240, Loss: 0.5826388322286473\n","Step 241, Loss: 0.5823717290346734\n","Step 242, Loss: 0.5821054242290467\n","Step 243, Loss: 0.5818399127054394\n","Step 244, Loss: 0.5815751894019691\n","Step 245, Loss: 0.5813112493007505\n","Step 246, Loss: 0.5810480874274547\n","Step 247, Loss: 0.5807856988508704\n","Step 248, Loss: 0.580524078682472\n","Step 249, Loss: 0.5802632220759909\n","Step 250, Loss: 0.5800031242269923\n","Step 251, Loss: 0.5797437803724564\n","Step 252, Loss: 0.5794851857903643\n","Step 253, Loss: 0.5792273357992871\n","Step 254, Loss: 0.5789702257579815\n","Step 255, Loss: 0.5787138510649882\n","Step 256, Loss: 0.5784582071582355\n","Step 257, Loss: 0.5782032895146463\n","Step 258, Loss: 0.5779490936497503\n","Step 259, Loss: 0.5776956151173\n","Step 260, Loss: 0.5774428495088906\n","Step 261, Loss: 0.5771907924535838\n","Step 262, Loss: 0.5769394396175372\n","Step 263, Loss: 0.5766887867036352\n","Step 264, Loss: 0.5764388294511262\n","Step 265, Loss: 0.5761895636352623\n","Step 266, Loss: 0.5759409850669431\n","Step 267, Loss: 0.5756930895923645\n","Step 268, Loss: 0.575445873092669\n","Step 269, Loss: 0.575199331483602\n","Step 270, Loss: 0.5749534607151705\n","Step 271, Loss: 0.5747082567713064\n","Step 272, Loss: 0.5744637156695317\n","Step 273, Loss: 0.5742198334606299\n","Step 274, Loss: 0.5739766062283181\n","Step 275, Loss: 0.5737340300889253\n","Step 276, Loss: 0.5734921011910721\n","Step 277, Loss: 0.5732508157153541\n","Step 278, Loss: 0.5730101698740309\n","Step 279, Loss: 0.5727701599107146\n","Step 280, Loss: 0.5725307821000658\n","Step 281, Loss: 0.5722920327474889\n","Step 282, Loss: 0.5720539081888341\n","Step 283, Loss: 0.5718164047900999\n","Step 284, Loss: 0.5715795189471409\n","Step 285, Loss: 0.5713432470853774\n","Step 286, Loss: 0.571107585659508\n","Step 287, Loss: 0.5708725311532262\n","Step 288, Loss: 0.5706380800789397\n","Step 289, Loss: 0.570404228977492\n","Step 290, Loss: 0.570170974417888\n","Step 291, Loss: 0.5699383129970219\n","Step 292, Loss: 0.5697062413394076\n","Step 293, Loss: 0.5694747560969138\n","Step 294, Loss: 0.5692438539484987\n","Step 295, Loss: 0.5690135315999516\n","Step 296, Loss: 0.5687837857836333\n","Step 297, Loss: 0.568554613258222\n","Step 298, Loss: 0.5683260108084605\n","Step 299, Loss: 0.5680979752449065\n","Step 300, Loss: 0.5678705034036862\n","Step 301, Loss: 0.5676435921462488\n","Step 302, Loss: 0.5674172383591258\n","Step 303, Loss: 0.5671914389536911\n","Step 304, Loss: 0.5669661908659235\n","Step 305, Loss: 0.5667414910561742\n","Step 306, Loss: 0.5665173365089339\n","Step 307, Loss: 0.566293724232603\n","Step 308, Loss: 0.566070651259266\n","Step 309, Loss: 0.565848114644466\n","Step 310, Loss: 0.5656261114669829\n","Step 311, Loss: 0.5654046388286134\n","Step 312, Loss: 0.5651836938539535\n","Step 313, Loss: 0.564963273690184\n","Step 314, Loss: 0.564743375506856\n","Step 315, Loss: 0.5645239964956816\n","Step 316, Loss: 0.5643051338703249\n","Step 317, Loss: 0.5640867848661955\n","Step 318, Loss: 0.5638689467402443\n","Step 319, Loss: 0.5636516167707618\n","Step 320, Loss: 0.5634347922571781\n","Step 321, Loss: 0.5632184705198646\n","Step 322, Loss: 0.5630026488999389\n","Step 323, Loss: 0.562787324759071\n","Step 324, Loss: 0.5625724954792907\n","Step 325, Loss: 0.5623581584627992\n","Step 326, Loss: 0.5621443111317802\n","Step 327, Loss: 0.5619309509282152\n","Step 328, Loss: 0.561718075313699\n","Step 329, Loss: 0.5615056817692575\n","Step 330, Loss: 0.5612937677951686\n","Step 331, Loss: 0.561082330910783\n","Step 332, Loss: 0.5608713686543488\n","Step 333, Loss: 0.5606608785828362\n","Step 334, Loss: 0.5604508582717653\n","Step 335, Loss: 0.5602413053150352\n","Step 336, Loss: 0.5600322173247545\n","Step 337, Loss: 0.5598235919310742\n","Step 338, Loss: 0.5596154267820218\n","Step 339, Loss: 0.5594077195433377\n","Step 340, Loss: 0.5592004678983129\n","Step 341, Loss: 0.5589936695476277\n","Step 342, Loss: 0.5587873222091937\n","Step 343, Loss: 0.5585814236179961\n","Step 344, Loss: 0.5583759715259377\n","Step 345, Loss: 0.5581709637016854\n","Step 346, Loss: 0.557966397930517\n","Step 347, Loss: 0.5577622720141712\n","Step 348, Loss: 0.5575585837706968\n","Step 349, Loss: 0.5573553310343063\n","Step 350, Loss: 0.5571525116552289\n","Step 351, Loss: 0.5569501234995651\n","Step 352, Loss: 0.5567481644491439\n","Step 353, Loss: 0.556546632401381\n","Step 354, Loss: 0.556345525269138\n","Step 355, Loss: 0.5561448409805835\n","Step 356, Loss: 0.5559445774790552\n","Step 357, Loss: 0.555744732722924\n","Step 358, Loss: 0.5555453046854587\n","Step 359, Loss: 0.5553462913546932\n","Step 360, Loss: 0.5551476907332936\n","Step 361, Loss: 0.554949500838428\n","Step 362, Loss: 0.5547517197016365\n","Step 363, Loss: 0.5545543453687036\n","Step 364, Loss: 0.5543573758995308\n","Step 365, Loss: 0.5541608093680115\n","Step 366, Loss: 0.5539646438619062\n","Step 367, Loss: 0.5537688774827197\n","Step 368, Loss: 0.5535735083455793\n","Step 369, Loss: 0.5533785345791138\n","Step 370, Loss: 0.5531839543253346\n","Step 371, Loss: 0.5529897657395177\n","Step 372, Loss: 0.5527959669900857\n","Step 373, Loss: 0.5526025562584929\n","Step 374, Loss: 0.5524095317391101\n","Step 375, Loss: 0.5522168916391113\n","Step 376, Loss: 0.5520246341783611\n","Step 377, Loss: 0.5518327575893043\n","Step 378, Loss: 0.5516412601168539\n","Step 379, Loss: 0.5514501400182841\n","Step 380, Loss: 0.5512593955631206\n","Step 381, Loss: 0.5510690250330352\n","Step 382, Loss: 0.5508790267217387\n","Step 383, Loss: 0.550689398934877\n","Step 384, Loss: 0.5505001399899264\n","Step 385, Loss: 0.550311248216092\n","Step 386, Loss: 0.5501227219542054\n","Step 387, Loss: 0.5499345595566237\n","Step 388, Loss: 0.5497467593871307\n","Step 389, Loss: 0.5495593198208372\n","Step 390, Loss: 0.5493722392440835\n","Step 391, Loss: 0.5491855160543435\n","Step 392, Loss: 0.5489991486601277\n","Step 393, Loss: 0.5488131354808888\n","Step 394, Loss: 0.548627474946928\n","Step 395, Loss: 0.5484421654993014\n","Step 396, Loss: 0.5482572055897285\n","Step 397, Loss: 0.5480725936805004\n","Step 398, Loss: 0.5478883282443903\n","Step 399, Loss: 0.5477044077645629\n","Step 400, Loss: 0.5475208307344869\n","Step 401, Loss: 0.5473375956578467\n","Step 402, Loss: 0.5471547010484559\n","Step 403, Loss: 0.546972145430171\n","Step 404, Loss: 0.5467899273368066\n","Step 405, Loss: 0.5466080453120506\n","Step 406, Loss: 0.5464264979093814\n","Step 407, Loss: 0.5462452836919842\n","Step 408, Loss: 0.5460644012326703\n","Step 409, Loss: 0.545883849113795\n","Step 410, Loss: 0.5457036259271775\n","Step 411, Loss: 0.545523730274022\n","Step 412, Loss: 0.5453441607648383\n","Step 413, Loss: 0.5451649160193639\n","Step 414, Loss: 0.5449859946664868\n","Step 415, Loss: 0.5448073953441688\n","Step 416, Loss: 0.5446291166993704\n","Step 417, Loss: 0.5444511573879751\n","Step 418, Loss: 0.5442735160747151\n","Step 419, Loss: 0.5440961914330977\n","Step 420, Loss: 0.5439191821453327\n","Step 421, Loss: 0.5437424869022605\n","Step 422, Loss: 0.5435661044032795\n","Step 423, Loss: 0.5433900333562759\n","Step 424, Loss: 0.5432142724775539\n","Step 425, Loss: 0.5430388204917657\n","Step 426, Loss: 0.5428636761318428\n","Step 427, Loss: 0.5426888381389278\n","Step 428, Loss: 0.5425143052623069\n","Step 429, Loss: 0.5423400762593433\n","Step 430, Loss: 0.5421661498954108\n","Step 431, Loss: 0.5419925249438273\n","Step 432, Loss: 0.5418192001857918\n","Step 433, Loss: 0.5416461744103181\n","Step 434, Loss: 0.5414734464141719\n","Step 435, Loss: 0.5413010150018077\n","Step 436, Loss: 0.5411288789853057\n","Step 437, Loss: 0.5409570371843105\n","Step 438, Loss: 0.5407854884259693\n","Step 439, Loss: 0.5406142315448712\n","Step 440, Loss: 0.5404432653829865\n","Step 441, Loss: 0.540272588789608\n","Step 442, Loss: 0.5401022006212912\n","Step 443, Loss: 0.5399320997417957\n","Step 444, Loss: 0.5397622850220272\n","Step 445, Loss: 0.5395927553399804\n","Step 446, Loss: 0.5394235095806819\n","Step 447, Loss: 0.5392545466361336\n","Step 448, Loss: 0.5390858654052567\n","Step 449, Loss: 0.5389174647938372\n","Step 450, Loss: 0.5387493437144697\n","Step 451, Loss: 0.5385815010865045\n","Step 452, Loss: 0.5384139358359924\n","Step 453, Loss: 0.5382466468956328\n","Step 454, Loss: 0.5380796332047195\n","Step 455, Loss: 0.5379128937090891\n","Step 456, Loss: 0.5377464273610695\n","Step 457, Loss: 0.5375802331194273\n","Step 458, Loss: 0.537414309949318\n","Step 459, Loss: 0.5372486568222352\n","Step 460, Loss: 0.5370832727159606\n","Step 461, Loss: 0.5369181566145144\n","Step 462, Loss: 0.5367533075081063\n","Step 463, Loss: 0.5365887243930871\n","Step 464, Loss: 0.5364244062719002\n","Step 465, Loss: 0.5362603521530342\n","Step 466, Loss: 0.5360965610509754\n","Step 467, Loss: 0.5359330319861609\n","Step 468, Loss: 0.5357697639849324\n","Step 469, Loss: 0.5356067560794899\n","Step 470, Loss: 0.5354440073078468\n","Step 471, Loss: 0.5352815167137838\n","Step 472, Loss: 0.5351192833468044\n","Step 473, Loss: 0.5349573062620913\n","Step 474, Loss: 0.5347955845204613\n","Step 475, Loss: 0.5346341171883231\n","Step 476, Loss: 0.5344729033376326\n","Step 477, Loss: 0.5343119420458515\n","Step 478, Loss: 0.5341512323959041\n","Step 479, Loss: 0.5339907734761355\n","Step 480, Loss: 0.5338305643802702\n","Step 481, Loss: 0.5336706042073706\n","Step 482, Loss: 0.5335108920617965\n","Step 483, Loss: 0.5333514270531639\n","Step 484, Loss: 0.5331922082963059\n","Step 485, Loss: 0.5330332349112316\n","Step 486, Loss: 0.5328745060230881\n","Step 487, Loss: 0.5327160207621202\n","Step 488, Loss: 0.532557778263633\n","Step 489, Loss: 0.5323997776679518\n","Step 490, Loss: 0.5322420181203856\n","Step 491, Loss: 0.5320844987711888\n","Step 492, Loss: 0.5319272187755241\n","Step 493, Loss: 0.5317701772934245\n","Step 494, Loss: 0.5316133734897582\n","Step 495, Loss: 0.5314568065341911\n","Step 496, Loss: 0.531300475601151\n","Step 497, Loss: 0.5311443798697921\n","Step 498, Loss: 0.5309885185239593\n","Step 499, Loss: 0.5308328907521535\n","Step 500, Loss: 0.5306774957474961\n","Step 501, Loss: 0.5305223327076956\n","Step 502, Loss: 0.5303674008350121\n","Step 503, Loss: 0.5302126993362247\n","Step 504, Loss: 0.5300582274225972\n","Step 505, Loss: 0.5299039843098449\n","Step 506, Loss: 0.5297499692181018\n","Step 507, Loss: 0.5295961813718877\n","Step 508, Loss: 0.529442620000076\n","Step 509, Loss: 0.5292892843358614\n","Step 510, Loss: 0.5291361736167279\n","Step 511, Loss: 0.528983287084418\n","Step 512, Loss: 0.5288306239849\n","Step 513, Loss: 0.5286781835683385\n","Step 514, Loss: 0.5285259650890629\n","Step 515, Loss: 0.5283739678055367\n","Step 516, Loss: 0.5282221909803277\n","Step 517, Loss: 0.5280706338800778\n","Step 518, Loss: 0.5279192957754737\n","Step 519, Loss: 0.5277681759412168\n","Step 520, Loss: 0.5276172736559946\n","Step 521, Loss: 0.5274665882024515\n","Step 522, Loss: 0.5273161188671601\n","Step 523, Loss: 0.5271658649405928\n","Step 524, Loss: 0.5270158257170937\n","Step 525, Loss: 0.5268660004948504\n","Step 526, Loss: 0.526716388575867\n","Step 527, Loss: 0.5265669892659351\n","Step 528, Loss: 0.5264178018746086\n","Step 529, Loss: 0.526268825715175\n","Step 530, Loss: 0.5261200601046292\n","Step 531, Loss: 0.5259715043636475\n","Step 532, Loss: 0.5258231578165604\n","Step 533, Loss: 0.5256750197913271\n","Step 534, Loss: 0.5255270896195097\n","Step 535, Loss: 0.5253793666362462\n","Step 536, Loss: 0.5252318501802277\n","Step 537, Loss: 0.5250845395936704\n","Step 538, Loss: 0.5249374342222923\n","Step 539, Loss: 0.524790533415288\n","Step 540, Loss: 0.524643836525304\n","Step 541, Loss: 0.5244973429084141\n","Step 542, Loss: 0.5243510519240958\n","Step 543, Loss: 0.5242049629352059\n","Step 544, Loss: 0.524059075307957\n","Step 545, Loss: 0.5239133884118935\n","Step 546, Loss: 0.5237679016198691\n","Step 547, Loss: 0.5236226143080224\n","Step 548, Loss: 0.5234775258557548\n","Step 549, Loss: 0.5233326356457079\n","Step 550, Loss: 0.5231879430637401\n","Step 551, Loss: 0.5230434474989045\n","Step 552, Loss: 0.5228991483434273\n","Step 553, Loss: 0.5227550449926847\n","Step 554, Loss: 0.5226111368451821\n","Step 555, Loss: 0.5224674233025315\n","Step 556, Loss: 0.5223239037694306\n","Step 557, Loss: 0.5221805776536416\n","Step 558, Loss: 0.5220374443659693\n","Step 559, Loss: 0.5218945033202411\n","Step 560, Loss: 0.5217517539332857\n","Step 561, Loss: 0.5216091956249123\n","Step 562, Loss: 0.5214668278178907\n","Step 563, Loss: 0.5213246499379304\n","Step 564, Loss: 0.5211826614136612\n","Step 565, Loss: 0.5210408616766127\n","Step 566, Loss: 0.5208992501611948\n","Step 567, Loss: 0.5207578263046779\n","Step 568, Loss: 0.5206165895471735\n","Step 569, Loss: 0.5204755393316151\n","Step 570, Loss: 0.5203346751037388\n","Step 571, Loss: 0.5201939963120645\n","Step 572, Loss: 0.520053502407877\n","Step 573, Loss: 0.5199131928452073\n","Step 574, Loss: 0.519773067080814\n","Step 575, Loss: 0.5196331245741653\n","Step 576, Loss: 0.5194933647874205\n","Step 577, Loss: 0.5193537871854115\n","Step 578, Loss: 0.5192143912356257\n","Step 579, Loss: 0.5190751764081881\n","Step 580, Loss: 0.5189361421758429\n","Step 581, Loss: 0.5187972880139365\n","Step 582, Loss: 0.5186586134004006\n","Step 583, Loss: 0.5185201178157343\n","Step 584, Loss: 0.5183818007429871\n","Step 585, Loss: 0.5182436616677425\n","Step 586, Loss: 0.5181057000781004\n","Step 587, Loss: 0.5179679154646613\n","Step 588, Loss: 0.5178303073205089\n","Step 589, Loss: 0.5176928751411946\n","Step 590, Loss: 0.5175556184247202\n","Step 591, Loss: 0.5174185366715227\n","Step 592, Loss: 0.5172816293844582\n","Step 593, Loss: 0.5171448960687848\n","Step 594, Loss: 0.5170083362321485\n","Step 595, Loss: 0.5168719493845668\n","Step 596, Loss: 0.516735735038413\n","Step 597, Loss: 0.5165996927084009\n","Step 598, Loss: 0.5164638219115704\n","Step 599, Loss: 0.5163281221672706\n","Step 600, Loss: 0.5161925929971468\n","Step 601, Loss: 0.5160572339251239\n","Step 602, Loss: 0.5159220444773929\n","Step 603, Loss: 0.515787024182395\n","Step 604, Loss: 0.5156521725708083\n","Step 605, Loss: 0.5155174891755326\n","Step 606, Loss: 0.5153829735316753\n","Step 607, Loss: 0.5152486251765367\n","Step 608, Loss: 0.5151144436495969\n","Step 609, Loss: 0.5149804284925008\n","Step 610, Loss: 0.514846579249045\n","Step 611, Loss: 0.5147128954651636\n","Step 612, Loss: 0.5145793766889144\n","Step 613, Loss: 0.5144460224704657\n","Step 614, Loss: 0.5143128323620828\n","Step 615, Loss: 0.5141798059181143\n","Step 616, Loss: 0.5140469426949796\n","Step 617, Loss: 0.5139142422511543\n","Step 618, Loss: 0.5137817041471594\n","Step 619, Loss: 0.5136493279455461\n","Step 620, Loss: 0.5135171132108842\n","Step 621, Loss: 0.5133850595097493\n","Step 622, Loss: 0.5132531664107097\n","Step 623, Loss: 0.5131214334843144\n","Step 624, Loss: 0.5129898603030799\n","Step 625, Loss: 0.5128584464414787\n","Step 626, Loss: 0.5127271914759266\n","Step 627, Loss: 0.5125960949847705\n","Step 628, Loss: 0.5124651565482764\n","Step 629, Loss: 0.5123343757486174\n","Step 630, Loss: 0.5122037521698617\n","Step 631, Loss: 0.5120732853979615\n","Step 632, Loss: 0.5119429750207404\n","Step 633, Loss: 0.5118128206278817\n","Step 634, Loss: 0.5116828218109181\n","Step 635, Loss: 0.5115529781632187\n","Step 636, Loss: 0.5114232892799789\n","Step 637, Loss: 0.5112937547582084\n","Step 638, Loss: 0.5111643741967205\n","Step 639, Loss: 0.5110351471961203\n","Step 640, Loss: 0.5109060733587943\n","Step 641, Loss: 0.5107771522888997\n","Step 642, Loss: 0.5106483835923525\n","Step 643, Loss: 0.5105197668768178\n","Step 644, Loss: 0.5103913017516986\n","Step 645, Loss: 0.510262987828125\n","Step 646, Loss: 0.5101348247189444\n","Step 647, Loss: 0.5100068120387105\n","Step 648, Loss: 0.5098789494036727\n","Step 649, Loss: 0.5097512364317665\n","Step 650, Loss: 0.5096236727426027\n","Step 651, Loss: 0.5094962579574578\n","Step 652, Loss: 0.5093689916992632\n","Step 653, Loss: 0.5092418735925959\n","Step 654, Loss: 0.5091149032636683\n","Step 655, Loss: 0.5089880803403182\n","Step 656, Loss: 0.5088614044519993\n","Step 657, Loss: 0.5087348752297718\n","Step 658, Loss: 0.5086084923062916\n","Step 659, Loss: 0.5084822553158019\n","Step 660, Loss: 0.5083561638941239\n","Step 661, Loss: 0.5082302176786461\n","Step 662, Loss: 0.5081044163083155\n","Step 663, Loss: 0.5079787594236296\n","Step 664, Loss: 0.5078532466666249\n","Step 665, Loss: 0.5077278776808697\n","Step 666, Loss: 0.5076026521114543\n","Step 667, Loss: 0.5074775696049815\n","Step 668, Loss: 0.5073526298095585\n","Step 669, Loss: 0.5072278323747877\n","Step 670, Loss: 0.5071031769517578\n","Step 671, Loss: 0.5069786631930351\n","Step 672, Loss: 0.5068542907526545\n","Step 673, Loss: 0.506730059286112\n","Step 674, Loss: 0.5066059684503548\n","Step 675, Loss: 0.5064820179037731\n","Step 676, Loss: 0.5063582073061929\n","Step 677, Loss: 0.5062345363188654\n","Step 678, Loss: 0.5061110046044611\n","Step 679, Loss: 0.5059876118270596\n","Step 680, Loss: 0.5058643576521427\n","Step 681, Loss: 0.5057412417465853\n","Step 682, Loss: 0.5056182637786483\n","Step 683, Loss: 0.5054954234179698\n","Step 684, Loss: 0.5053727203355575\n","Step 685, Loss: 0.5052501542037804\n","Step 686, Loss: 0.5051277246963619\n","Step 687, Loss: 0.5050054314883707\n","Step 688, Loss: 0.5048832742562143\n","Step 689, Loss: 0.5047612526776304\n","Step 690, Loss: 0.5046393664316798\n","Step 691, Loss: 0.5045176151987387\n","Step 692, Loss: 0.5043959986604911\n","Step 693, Loss: 0.5042745164999214\n","Step 694, Loss: 0.504153168401307\n","Step 695, Loss: 0.5040319540502107\n","Step 696, Loss: 0.5039108731334743\n","Step 697, Loss: 0.5037899253392097\n","Step 698, Loss: 0.5036691103567936\n","Step 699, Loss: 0.5035484278768588\n","Step 700, Loss: 0.5034278775912879\n","Step 701, Loss: 0.5033074591932062\n","Step 702, Loss: 0.5031871723769743\n","Step 703, Loss: 0.5030670168381814\n","Step 704, Loss: 0.5029469922736389\n","Step 705, Loss: 0.5028270983813725\n","Step 706, Loss: 0.5027073348606161\n","Step 707, Loss: 0.502587701411805\n","Step 708, Loss: 0.5024681977365688\n","Step 709, Loss: 0.5023488235377256\n","Step 710, Loss: 0.5022295785192739\n","Step 711, Loss: 0.5021104623863875\n","Step 712, Loss: 0.5019914748454084\n","Step 713, Loss: 0.5018726156038401\n","Step 714, Loss: 0.5017538843703413\n","Step 715, Loss: 0.5016352808547199\n","Step 716, Loss: 0.5015168047679257\n","Step 717, Loss: 0.5013984558220455\n","Step 718, Loss: 0.5012802337302954\n","Step 719, Loss: 0.5011621382070156\n","Step 720, Loss: 0.5010441689676637\n","Step 721, Loss: 0.5009263257288088\n","Step 722, Loss: 0.5008086082081251\n","Step 723, Loss: 0.5006910161243865\n","Step 724, Loss: 0.5005735491974598\n","Step 725, Loss: 0.5004562071482991\n","Step 726, Loss: 0.5003389896989402\n","Step 727, Loss: 0.500221896572494\n","Step 728, Loss: 0.5001049274931417\n","Step 729, Loss: 0.49998808218612734\n","Step 730, Loss: 0.49987136037775376\n","Step 731, Loss: 0.4997547617953759\n","Step 732, Loss: 0.4996382861673955\n","Step 733, Loss: 0.49952193322325505\n","Step 734, Loss: 0.49940570269343265\n","Step 735, Loss: 0.49928959430943615\n","Step 736, Loss: 0.49917360780379766\n","Step 737, Loss: 0.4990577429100681\n","Step 738, Loss: 0.49894199936281164\n","Step 739, Loss: 0.49882637689760034\n","Step 740, Loss: 0.4987108752510091\n","Step 741, Loss: 0.4985954941606092\n","Step 742, Loss: 0.49848023336496466\n","Step 743, Loss: 0.4983650926036255\n","Step 744, Loss: 0.498250071617123\n","Step 745, Loss: 0.4981351701469648\n","Step 746, Loss: 0.49802038793562947\n","Step 747, Loss: 0.49790572472656114\n","Step 748, Loss: 0.49779118026416463\n","Step 749, Loss: 0.49767675429380065\n","Step 750, Loss: 0.49756244656178\n","Step 751, Loss: 0.4974482568153594\n","Step 752, Loss: 0.497334184802736\n","Step 753, Loss: 0.4972202302730425\n","Step 754, Loss: 0.4971063929763425\n","Step 755, Loss: 0.4969926726636255\n","Step 756, Loss: 0.4968790690868016\n","Step 757, Loss: 0.4967655819986973\n","Step 758, Loss: 0.4966522111530508\n","Step 759, Loss: 0.4965389563045067\n","Step 760, Loss: 0.4964258172086115\n","Step 761, Loss: 0.49631279362180897\n","Step 762, Loss: 0.4961998853014357\n","Step 763, Loss: 0.49608709200571594\n","Step 764, Loss: 0.49597441349375765\n","Step 765, Loss: 0.49586184952554735\n","Step 766, Loss: 0.4957493998619459\n","Step 767, Loss: 0.495637064264684\n","Step 768, Loss: 0.4955248424963575\n","Step 769, Loss: 0.49541273432042343\n","Step 770, Loss: 0.4953007395011948\n","Step 771, Loss: 0.4951888578038369\n","Step 772, Loss: 0.49507708899436303\n","Step 773, Loss: 0.49496543283962896\n","Step 774, Loss: 0.4948538891073304\n","Step 775, Loss: 0.4947424575659973\n","Step 776, Loss: 0.49463113798499025\n","Step 777, Loss: 0.4945199301344962\n","Step 778, Loss: 0.49440883378552397\n","Step 779, Loss: 0.49429784870990073\n","Step 780, Loss: 0.4941869746802669\n","Step 781, Loss: 0.4940762114700729\n","Step 782, Loss: 0.49396555885357474\n","Step 783, Loss: 0.49385501660582964\n","Step 784, Loss: 0.49374458450269254\n","Step 785, Loss: 0.49363426232081187\n","Step 786, Loss: 0.49352404983762527\n","Step 787, Loss: 0.49341394683135614\n","Step 788, Loss: 0.49330395308100944\n","Step 789, Loss: 0.4931940683663676\n","Step 790, Loss: 0.4930842924679869\n","Step 791, Loss: 0.49297462516719365\n","Step 792, Loss: 0.4928650662460803\n","Step 793, Loss: 0.4927556154875011\n","Step 794, Loss: 0.49264627267506944\n","Step 795, Loss: 0.49253703759315276\n","Step 796, Loss: 0.4924279100268699\n","Step 797, Loss: 0.492318889762087\n","Step 798, Loss: 0.4922099765854133\n","Step 799, Loss: 0.49210117028419836\n","Step 800, Loss: 0.4919924706465276\n","Step 801, Loss: 0.4918838774612196\n","Step 802, Loss: 0.49177539051782126\n","Step 803, Loss: 0.4916670096066055\n","Step 804, Loss: 0.4915587345185665\n","Step 805, Loss: 0.4914505650454174\n","Step 806, Loss: 0.49134250097958576\n","Step 807, Loss: 0.49123454211421047\n","Step 808, Loss: 0.49112668824313843\n","Step 809, Loss: 0.4910189391609208\n","Step 810, Loss: 0.4909112946628097\n","Step 811, Loss: 0.49080375454475506\n","Step 812, Loss: 0.4906963186034005\n","Step 813, Loss: 0.4905889866360811\n","Step 814, Loss: 0.4904817584408187\n","Step 815, Loss: 0.4903746338163197\n","Step 816, Loss: 0.49026761256197143\n","Step 817, Loss: 0.49016069447783844\n","Step 818, Loss: 0.49005387936465983\n","Step 819, Loss: 0.4899471670238455\n","Step 820, Loss: 0.48984055725747344\n","Step 821, Loss: 0.4897340498682861\n","Step 822, Loss: 0.48962764465968744\n","Step 823, Loss: 0.48952134143573955\n","Step 824, Loss: 0.4894151400011598\n","Step 825, Loss: 0.48930904016131754\n","Step 826, Loss: 0.489203041722231\n","Step 827, Loss: 0.4890971444905639\n","Step 828, Loss: 0.48899134827362334\n","Step 829, Loss: 0.48888565287935537\n","Step 830, Loss: 0.48878005811634323\n","Step 831, Loss: 0.4886745637938036\n","Step 832, Loss: 0.48856916972158376\n","Step 833, Loss: 0.4884638757101586\n","Step 834, Loss: 0.4883586815706277\n","Step 835, Loss: 0.48825358711471284\n","Step 836, Loss: 0.4881485921547538\n","Step 837, Loss: 0.48804369650370705\n","Step 838, Loss: 0.48793889997514145\n","Step 839, Loss: 0.48783420238323655\n","Step 840, Loss: 0.4877296035427787\n","Step 841, Loss: 0.4876251032691593\n","Step 842, Loss: 0.4875207013783709\n","Step 843, Loss: 0.487416397687005\n","Step 844, Loss: 0.4873121920122491\n","Step 845, Loss: 0.48720808417188427\n","Step 846, Loss: 0.4871040739842817\n","Step 847, Loss: 0.4870001612684005\n","Step 848, Loss: 0.48689634584378483\n","Step 849, Loss: 0.48679262753056135\n","Step 850, Loss: 0.48668900614943594\n","Step 851, Loss: 0.486585481521692\n","Step 852, Loss: 0.4864820534691868\n","Step 853, Loss: 0.4863787218143497\n","Step 854, Loss: 0.48627548638017865\n","Step 855, Loss: 0.48617234699023815\n","Step 856, Loss: 0.48606930346865695\n","Step 857, Loss: 0.48596635564012436\n","Step 858, Loss: 0.4858635033298889\n","Step 859, Loss: 0.4857607463637551\n","Step 860, Loss: 0.485658084568081\n","Step 861, Loss: 0.4855555177697758\n","Step 862, Loss: 0.48545304579629694\n","Step 863, Loss: 0.4853506684756484\n","Step 864, Loss: 0.4852483856363774\n","Step 865, Loss: 0.4851461971075725\n","Step 866, Loss: 0.4850441027188608\n","Step 867, Loss: 0.4849421023004055\n","Step 868, Loss: 0.4848401956829041\n","Step 869, Loss: 0.48473838269758496\n","Step 870, Loss: 0.48463666317620574\n","Step 871, Loss: 0.48453503695105055\n","Step 872, Loss: 0.484433503854928\n","Step 873, Loss: 0.48433206372116844\n","Step 874, Loss: 0.48423071638362175\n","Step 875, Loss: 0.4841294616766552\n","Step 876, Loss: 0.4840282994351509\n","Step 877, Loss: 0.4839272294945035\n","Step 878, Loss: 0.4838262516906181\n","Step 879, Loss: 0.4837253658599078\n","Step 880, Loss: 0.48362457183929175\n","Step 881, Loss: 0.4835238694661922\n","Step 882, Loss: 0.48342325857853313\n","Step 883, Loss: 0.4833227390147375\n","Step 884, Loss: 0.4832223106137249\n","Step 885, Loss: 0.48312197321490996\n","Step 886, Loss: 0.48302172665819987\n","Step 887, Loss: 0.48292157078399145\n","Step 888, Loss: 0.4828215054331707\n","Step 889, Loss: 0.48272153044710897\n","Step 890, Loss: 0.4826216456676617\n","Step 891, Loss: 0.4825218509371661\n","Step 892, Loss: 0.4824221460984388\n","Step 893, Loss: 0.48232253099477446\n","Step 894, Loss: 0.4822230054699427\n","Step 895, Loss: 0.4821235693681868\n","Step 896, Loss: 0.4820242225342213\n","Step 897, Loss: 0.4819249648132301\n","Step 898, Loss: 0.4818257960508639\n","Step 899, Loss: 0.48172671609323936\n","Step 900, Loss: 0.48162772478693566\n","Step 901, Loss: 0.48152882197899327\n","Step 902, Loss: 0.4814300075169119\n","Step 903, Loss: 0.4813312812486486\n","Step 904, Loss: 0.48123264302261537\n","Step 905, Loss: 0.4811340926876775\n","Step 906, Loss: 0.4810356300931516\n","Step 907, Loss: 0.4809372550888037\n","Step 908, Loss: 0.48083896752484706\n","Step 909, Loss: 0.4807407672519406\n","Step 910, Loss: 0.48064265412118684\n","Step 911, Loss: 0.4805446279841298\n","Step 912, Loss: 0.4804466886927533\n","Step 913, Loss: 0.4803488360994793\n","Step 914, Loss: 0.4802510700571655\n","Step 915, Loss: 0.48015339041910393\n","Step 916, Loss: 0.48005579703901907\n","Step 917, Loss: 0.4799582897710656\n","Step 918, Loss: 0.47986086846982723\n","Step 919, Loss: 0.4797635329903141\n","Step 920, Loss: 0.4796662831879616\n","Step 921, Loss: 0.4795691189186285\n","Step 922, Loss: 0.47947204003859484\n","Step 923, Loss: 0.4793750464045603\n","Step 924, Loss: 0.47927813787364243\n","Step 925, Loss: 0.47918131430337496\n","Step 926, Loss: 0.4790845755517063\n","Step 927, Loss: 0.47898792147699715\n","Step 928, Loss: 0.478891351938019\n","Step 929, Loss: 0.47879486679395294\n","Step 930, Loss: 0.4786984659043873\n","Step 931, Loss: 0.47860214912931626\n","Step 932, Loss: 0.4785059163291379\n","Step 933, Loss: 0.4784097673646528\n","Step 934, Loss: 0.47831370209706253\n","Step 935, Loss: 0.4782177203879672\n","Step 936, Loss: 0.47812182209936455\n","Step 937, Loss: 0.47802600709364834\n","Step 938, Loss: 0.47793027523360576\n","Step 939, Loss: 0.477834626382417\n","Step 940, Loss: 0.47773906040365316\n","Step 941, Loss: 0.47764357716127404\n","Step 942, Loss: 0.47754817651962717\n","Step 943, Loss: 0.4774528583434467\n","Step 944, Loss: 0.4773576224978505\n","Step 945, Loss: 0.47726246884833967\n","Step 946, Loss: 0.4771673972607964\n","Step 947, Loss: 0.4770724076014825\n","Step 948, Loss: 0.47697749973703835\n","Step 949, Loss: 0.47688267353448055\n","Step 950, Loss: 0.4767879288612008\n","Step 951, Loss: 0.4766932655849644\n","Step 952, Loss: 0.47659868357390867\n","Step 953, Loss: 0.47650418269654143\n","Step 954, Loss: 0.4764097628217394\n","Step 955, Loss: 0.4763154238187467\n","Step 956, Loss: 0.4762211655571738\n","Step 957, Loss: 0.4761269879069953\n","Step 958, Loss: 0.4760328907385487\n","Step 959, Loss: 0.4759388739225338\n","Step 960, Loss: 0.47584493733000965\n","Step 961, Loss: 0.47575108083239437\n","Step 962, Loss: 0.47565730430146314\n","Step 963, Loss: 0.4755636076093469\n","Step 964, Loss: 0.4754699906285311\n","Step 965, Loss: 0.4753764532318538\n","Step 966, Loss: 0.47528299529250473\n","Step 967, Loss: 0.4751896166840236\n","Step 968, Loss: 0.47509631728029894\n","Step 969, Loss: 0.4750030969555662\n","Step 970, Loss: 0.47490995558440724\n","Step 971, Loss: 0.4748168930417478\n","Step 972, Loss: 0.47472390920285734\n","Step 973, Loss: 0.47463100394334673\n","Step 974, Loss: 0.4745381771391674\n","Step 975, Loss: 0.47444542866660966\n","Step 976, Loss: 0.4743527584023017\n","Step 977, Loss: 0.47426016622320805\n","Step 978, Loss: 0.47416765200662814\n","Step 979, Loss: 0.47407521563019533\n","Step 980, Loss: 0.47398285697187503\n","Step 981, Loss: 0.47389057590996436\n","Step 982, Loss: 0.47379837232308936\n","Step 983, Loss: 0.47370624609020523\n","Step 984, Loss: 0.47361419709059405\n","Step 985, Loss: 0.4735222252038639\n","Step 986, Loss: 0.4734303303099473\n","Step 987, Loss: 0.47333851228910034\n","Step 988, Loss: 0.47324677102190116\n","Step 989, Loss: 0.47315510638924846\n","Step 990, Loss: 0.47306351827236093\n","Step 991, Loss: 0.47297200655277516\n","Step 992, Loss: 0.4728805711123451\n","Step 993, Loss: 0.4727892118332406\n","Step 994, Loss: 0.4726979285979457\n","Step 995, Loss: 0.47260672128925824\n","Step 996, Loss: 0.4725155897902882\n","Step 997, Loss: 0.4724245339844562\n","Step 998, Loss: 0.4723335537554932\n","Step 999, Loss: 0.47224264898743806\n","Accuracy: 0.85\n"]}]},{"cell_type":"markdown","source":["As a homework try to solve the following problem with logistic regression: Given a dimension n, detect if n dimensional vector is located in n dimensional sphere with a radius equal to 1."],"metadata":{"id":"dnZBmw4_RyO5"}}]}