{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "mount_file_id": "1PWbGOvZZg4shD-Y1m0ULHfIeHrzV3VL7",
   "authorship_tag": "ABX9TyNDHKJiKNUQmBNFOggQ5raE"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The optimization problem of logistic regression is a binary classification problem. Given a set of features $x$, we want to predict whether a sample belongs to one of two classes, which we'll call \"positive\" and \"negative\", i.e. $y=1$ or $0$. The loss of the problem is the sigmoid cross entropy loss, which has the following form\n",
    "$$L(θ) = -\\sum_{i} \\big[y_i log(\\hat{y}_i(θ) + (1 - y_i) log(1 - \\hat{y}_i(θ)\\big]$$\n",
    "where in our case $\\hat{y} = \\sigma (x^T\\theta)$ and $\\sigma$ is the sigmoid function, $z = x^T\\theta$ is called logit"
   ],
   "metadata": {
    "id": "5fR9OSTbdLA4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating a Dataset\n",
    "\n",
    "To create a dataset, we'll use scikit-learn's make_classification function, which generates a random n-class classification problem. We'll use two classes (n_classes=2) and generate 1000 samples with 10 features (n_features=10)."
   ],
   "metadata": {
    "id": "h3RXay8SPevK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_classification(n_samples=100, n_features=10, n_classes=2, class_sep=0.3, random_state=42)\n",
    "# Add intercept column to X (for bias)\n",
    "X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "# make y matrix\n",
    "y = y[:, np.newaxis]\n",
    "print(X.shape, y.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ym-bHRO-PmZw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1708583460080,
     "user_tz": -240,
     "elapsed": 278,
     "user": {
      "displayName": "Ստեփան Սարգսյան",
      "userId": "17563089324629164814"
     }
    },
    "outputId": "7f8204b4-71f4-432b-efac-2babd38f6106",
    "ExecuteTime": {
     "end_time": "2024-04-03T23:11:49.508843Z",
     "start_time": "2024-04-03T23:11:49.122421Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 11) (100, 1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we define a gradient descent function, i.e. apply the gradients and update the parameter values iteratively"
   ],
   "metadata": {
    "id": "ROKKGUuQMOGI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_cross_entropy(y, y_pred):\n",
    "    '''\n",
    "    y: labels\n",
    "    y_pred: probabilistic output in [0,1]\n",
    "    '''\n",
    "    assert y.shape == y_pred.shape, \"label and prediction shapes should be equal\"\n",
    "    L = -(np.mean(y*np.log(y_pred) + (1-y)*np.log(1-y_pred)))\n",
    "    return L\n",
    "\n",
    "def logistic_regression(X, y, learning_rate=0.01, num_iterations=1000):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros((n, 1))\n",
    "    for i in range(num_iterations):\n",
    "        z = np.dot(X, theta)\n",
    "        y_pred = sigmoid(z)\n",
    "        gradient = np.dot(X.T, (y_pred - y)) / m\n",
    "        theta = theta - learning_rate * gradient\n",
    "        loss = sigmoid_cross_entropy(y, y_pred)\n",
    "        print(f\"Step {i}, Loss: {loss}\")\n",
    "    return theta\n"
   ],
   "metadata": {
    "id": "N81wgVlcQ7Mp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1708583408240,
     "user_tz": -240,
     "elapsed": 4,
     "user": {
      "displayName": "Ստեփան Սարգսյան",
      "userId": "17563089324629164814"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-04-03T23:12:15.037504Z",
     "start_time": "2024-04-03T23:12:15.030846Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's evaluate the model"
   ],
   "metadata": {
    "id": "imOAFHALasjL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "theta = logistic_regression(X_train, y_train, num_iterations = 1000)\n",
    "y_pred = sigmoid(np.dot(X_test, theta)) > 0.5\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JXxNEAzqSM5P",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1708583464725,
     "user_tz": -240,
     "elapsed": 838,
     "user": {
      "displayName": "Ստեփան Սարգսյան",
      "userId": "17563089324629164814"
     }
    },
    "outputId": "cc6938de-ff0e-411c-fb1b-77bc64cb2374",
    "ExecuteTime": {
     "end_time": "2024-04-03T23:12:36.654282Z",
     "start_time": "2024-04-03T23:12:36.606280Z"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 0.6931471805599453\n",
      "Step 1, Loss: 0.692322107826435\n",
      "Step 2, Loss: 0.6915025000368387\n",
      "Step 3, Loss: 0.6906883095760641\n",
      "Step 4, Loss: 0.6898794891918815\n",
      "Step 5, Loss: 0.6890759919945875\n",
      "Step 6, Loss: 0.6882777714565933\n",
      "Step 7, Loss: 0.6874847814119394\n",
      "Step 8, Loss: 0.6866969760557391\n",
      "Step 9, Loss: 0.6859143099435524\n",
      "Step 10, Loss: 0.6851367379906931\n",
      "Step 11, Loss: 0.684364215471468\n",
      "Step 12, Loss: 0.6835966980183562\n",
      "Step 13, Loss: 0.6828341416211237\n",
      "Step 14, Loss: 0.6820765026258794\n",
      "Step 15, Loss: 0.6813237377340735\n",
      "Step 16, Loss: 0.6805758040014388\n",
      "Step 17, Loss: 0.6798326588368785\n",
      "Step 18, Loss: 0.6790942600013012\n",
      "Step 19, Loss: 0.6783605656064056\n",
      "Step 20, Loss: 0.6776315341134147\n",
      "Step 21, Loss: 0.6769071243317641\n",
      "Step 22, Loss: 0.6761872954177452\n",
      "Step 23, Loss: 0.6754720068731019\n",
      "Step 24, Loss: 0.6747612185435872\n",
      "Step 25, Loss: 0.6740548906174775\n",
      "Step 26, Loss: 0.6733529836240489\n",
      "Step 27, Loss: 0.6726554584320148\n",
      "Step 28, Loss: 0.6719622762479276\n",
      "Step 29, Loss: 0.6712733986145454\n",
      "Step 30, Loss: 0.6705887874091656\n",
      "Step 31, Loss: 0.6699084048419273\n",
      "Step 32, Loss: 0.6692322134540811\n",
      "Step 33, Loss: 0.6685601761162321\n",
      "Step 34, Loss: 0.6678922560265541\n",
      "Step 35, Loss: 0.6672284167089764\n",
      "Step 36, Loss: 0.6665686220113474\n",
      "Step 37, Loss: 0.6659128361035715\n",
      "Step 38, Loss: 0.6652610234757269\n",
      "Step 39, Loss: 0.6646131489361574\n",
      "Step 40, Loss: 0.6639691776095475\n",
      "Step 41, Loss: 0.6633290749349763\n",
      "Step 42, Loss: 0.6626928066639544\n",
      "Step 43, Loss: 0.6620603388584418\n",
      "Step 44, Loss: 0.6614316378888528\n",
      "Step 45, Loss: 0.6608066704320427\n",
      "Step 46, Loss: 0.6601854034692828\n",
      "Step 47, Loss: 0.6595678042842218\n",
      "Step 48, Loss: 0.6589538404608352\n",
      "Step 49, Loss: 0.658343479881363\n",
      "Step 50, Loss: 0.6577366907242382\n",
      "Step 51, Loss: 0.6571334414620058\n",
      "Step 52, Loss: 0.6565337008592322\n",
      "Step 53, Loss: 0.65593743797041\n",
      "Step 54, Loss: 0.6553446221378518\n",
      "Step 55, Loss: 0.6547552229895819\n",
      "Step 56, Loss: 0.6541692104372208\n",
      "Step 57, Loss: 0.6535865546738655\n",
      "Step 58, Loss: 0.6530072261719669\n",
      "Step 59, Loss: 0.6524311956812034\n",
      "Step 60, Loss: 0.6518584342263518\n",
      "Step 61, Loss: 0.6512889131051581\n",
      "Step 62, Loss: 0.6507226038862062\n",
      "Step 63, Loss: 0.6501594784067862\n",
      "Step 64, Loss: 0.6495995087707628\n",
      "Step 65, Loss: 0.6490426673464462\n",
      "Step 66, Loss: 0.6484889267644618\n",
      "Step 67, Loss: 0.6479382599156238\n",
      "Step 68, Loss: 0.6473906399488103\n",
      "Step 69, Loss: 0.6468460402688423\n",
      "Step 70, Loss: 0.646304434534365\n",
      "Step 71, Loss: 0.645765796655734\n",
      "Step 72, Loss: 0.6452301007929058\n",
      "Step 73, Loss: 0.6446973213533325\n",
      "Step 74, Loss: 0.644167432989863\n",
      "Step 75, Loss: 0.6436404105986491\n",
      "Step 76, Loss: 0.6431162293170571\n",
      "Step 77, Loss: 0.6425948645215882\n",
      "Step 78, Loss: 0.6420762918258035\n",
      "Step 79, Loss: 0.6415604870782569\n",
      "Step 80, Loss: 0.641047426360436\n",
      "Step 81, Loss: 0.640537085984711\n",
      "Step 82, Loss: 0.6400294424922913\n",
      "Step 83, Loss: 0.6395244726511911\n",
      "Step 84, Loss: 0.6390221534542024\n",
      "Step 85, Loss: 0.6385224621168808\n",
      "Step 86, Loss: 0.6380253760755359\n",
      "Step 87, Loss: 0.6375308729852345\n",
      "Step 88, Loss: 0.6370389307178133\n",
      "Step 89, Loss: 0.6365495273599004\n",
      "Step 90, Loss: 0.6360626412109487\n",
      "Step 91, Loss: 0.6355782507812784\n",
      "Step 92, Loss: 0.6350963347901314\n",
      "Step 93, Loss: 0.6346168721637364\n",
      "Step 94, Loss: 0.634139842033384\n",
      "Step 95, Loss: 0.633665223733515\n",
      "Step 96, Loss: 0.6331929967998184\n",
      "Step 97, Loss: 0.6327231409673422\n",
      "Step 98, Loss: 0.6322556361686146\n",
      "Step 99, Loss: 0.631790462531779\n",
      "Step 100, Loss: 0.6313276003787394\n",
      "Step 101, Loss: 0.6308670302233181\n",
      "Step 102, Loss: 0.6304087327694268\n",
      "Step 103, Loss: 0.6299526889092479\n",
      "Step 104, Loss: 0.6294988797214314\n",
      "Step 105, Loss: 0.6290472864693009\n",
      "Step 106, Loss: 0.6285978905990734\n",
      "Step 107, Loss: 0.6281506737380942\n",
      "Step 108, Loss: 0.6277056176930806\n",
      "Step 109, Loss: 0.6272627044483808\n",
      "Step 110, Loss: 0.6268219161642452\n",
      "Step 111, Loss: 0.6263832351751109\n",
      "Step 112, Loss: 0.6259466439878976\n",
      "Step 113, Loss: 0.6255121252803194\n",
      "Step 114, Loss: 0.6250796618992066\n",
      "Step 115, Loss: 0.6246492368588423\n",
      "Step 116, Loss: 0.6242208333393117\n",
      "Step 117, Loss: 0.6237944346848643\n",
      "Step 118, Loss: 0.6233700244022897\n",
      "Step 119, Loss: 0.622947586159306\n",
      "Step 120, Loss: 0.6225271037829609\n",
      "Step 121, Loss: 0.622108561258048\n",
      "Step 122, Loss: 0.621691942725533\n",
      "Step 123, Loss: 0.6212772324809961\n",
      "Step 124, Loss: 0.6208644149730859\n",
      "Step 125, Loss: 0.620453474801986\n",
      "Step 126, Loss: 0.6200443967178961\n",
      "Step 127, Loss: 0.6196371656195251\n",
      "Step 128, Loss: 0.6192317665525974\n",
      "Step 129, Loss: 0.6188281847083725\n",
      "Step 130, Loss: 0.6184264054221773\n",
      "Step 131, Loss: 0.6180264141719513\n",
      "Step 132, Loss: 0.6176281965768047\n",
      "Step 133, Loss: 0.6172317383955898\n",
      "Step 134, Loss: 0.6168370255254845\n",
      "Step 135, Loss: 0.6164440440005887\n",
      "Step 136, Loss: 0.6160527799905345\n",
      "Step 137, Loss: 0.6156632197991072\n",
      "Step 138, Loss: 0.6152753498628807\n",
      "Step 139, Loss: 0.6148891567498633\n",
      "Step 140, Loss: 0.6145046271581596\n",
      "Step 141, Loss: 0.6141217479146404\n",
      "Step 142, Loss: 0.6137405059736285\n",
      "Step 143, Loss: 0.6133608884155951\n",
      "Step 144, Loss: 0.612982882445869\n",
      "Step 145, Loss: 0.6126064753933578\n",
      "Step 146, Loss: 0.6122316547092812\n",
      "Step 147, Loss: 0.6118584079659171\n",
      "Step 148, Loss: 0.6114867228553581\n",
      "Step 149, Loss: 0.6111165871882819\n",
      "Step 150, Loss: 0.610747988892732\n",
      "Step 151, Loss: 0.6103809160129108\n",
      "Step 152, Loss: 0.6100153567079845\n",
      "Step 153, Loss: 0.6096512992508997\n",
      "Step 154, Loss: 0.6092887320272108\n",
      "Step 155, Loss: 0.6089276435339203\n",
      "Step 156, Loss: 0.6085680223783285\n",
      "Step 157, Loss: 0.6082098572768972\n",
      "Step 158, Loss: 0.6078531370541217\n",
      "Step 159, Loss: 0.6074978506414166\n",
      "Step 160, Loss: 0.6071439870760105\n",
      "Step 161, Loss: 0.6067915354998537\n",
      "Step 162, Loss: 0.606440485158535\n",
      "Step 163, Loss: 0.6060908254002111\n",
      "Step 164, Loss: 0.6057425456745456\n",
      "Step 165, Loss: 0.6053956355316582\n",
      "Step 166, Loss: 0.6050500846210866\n",
      "Step 167, Loss: 0.6047058826907566\n",
      "Step 168, Loss: 0.6043630195859647\n",
      "Step 169, Loss: 0.6040214852483687\n",
      "Step 170, Loss: 0.6036812697149914\n",
      "Step 171, Loss: 0.6033423631172317\n",
      "Step 172, Loss: 0.6030047556798881\n",
      "Step 173, Loss: 0.6026684377201905\n",
      "Step 174, Loss: 0.6023333996468434\n",
      "Step 175, Loss: 0.6019996319590776\n",
      "Step 176, Loss: 0.601667125245713\n",
      "Step 177, Loss: 0.6013358701842298\n",
      "Step 178, Loss: 0.6010058575398503\n",
      "Step 179, Loss: 0.6006770781646296\n",
      "Step 180, Loss: 0.6003495229965565\n",
      "Step 181, Loss: 0.600023183058663\n",
      "Step 182, Loss: 0.5996980494581431\n",
      "Step 183, Loss: 0.5993741133854812\n",
      "Step 184, Loss: 0.5990513661135897\n",
      "Step 185, Loss: 0.5987297989969551\n",
      "Step 186, Loss: 0.5984094034707936\n",
      "Step 187, Loss: 0.5980901710502151\n",
      "Step 188, Loss: 0.5977720933293963\n",
      "Step 189, Loss: 0.597455161980762\n",
      "Step 190, Loss: 0.5971393687541762\n",
      "Step 191, Loss: 0.5968247054761402\n",
      "Step 192, Loss: 0.5965111640490003\n",
      "Step 193, Loss: 0.5961987364501636\n",
      "Step 194, Loss: 0.5958874147313218\n",
      "Step 195, Loss: 0.5955771910176834\n",
      "Step 196, Loss: 0.5952680575072138\n",
      "Step 197, Loss: 0.5949600064698847\n",
      "Step 198, Loss: 0.5946530302469293\n",
      "Step 199, Loss: 0.5943471212501079\n",
      "Step 200, Loss: 0.5940422719609788\n",
      "Step 201, Loss: 0.5937384749301788\n",
      "Step 202, Loss: 0.5934357227767116\n",
      "Step 203, Loss: 0.5931340081872415\n",
      "Step 204, Loss: 0.592833323915397\n",
      "Step 205, Loss: 0.592533662781081\n",
      "Step 206, Loss: 0.5922350176697883\n",
      "Step 207, Loss: 0.5919373815319302\n",
      "Step 208, Loss: 0.5916407473821671\n",
      "Step 209, Loss: 0.5913451082987473\n",
      "Step 210, Loss: 0.5910504574228537\n",
      "Step 211, Loss: 0.5907567879579566\n",
      "Step 212, Loss: 0.5904640931691751\n",
      "Step 213, Loss: 0.5901723663826431\n",
      "Step 214, Loss: 0.5898816009848843\n",
      "Step 215, Loss: 0.5895917904221918\n",
      "Step 216, Loss: 0.5893029282000167\n",
      "Step 217, Loss: 0.5890150078823614\n",
      "Step 218, Loss: 0.5887280230911797\n",
      "Step 219, Loss: 0.5884419675057849\n",
      "Step 220, Loss: 0.5881568348622624\n",
      "Step 221, Loss: 0.5878726189528893\n",
      "Step 222, Loss: 0.5875893136255608\n",
      "Step 223, Loss: 0.5873069127832216\n",
      "Step 224, Loss: 0.5870254103833054\n",
      "Step 225, Loss: 0.5867448004371777\n",
      "Step 226, Loss: 0.5864650770095876\n",
      "Step 227, Loss: 0.5861862342181228\n",
      "Step 228, Loss: 0.5859082662326724\n",
      "Step 229, Loss: 0.5856311672748952\n",
      "Step 230, Loss: 0.5853549316176923\n",
      "Step 231, Loss: 0.5850795535846871\n",
      "Step 232, Loss: 0.5848050275497109\n",
      "Step 233, Loss: 0.5845313479362926\n",
      "Step 234, Loss: 0.5842585092171546\n",
      "Step 235, Loss: 0.5839865059137155\n",
      "Step 236, Loss: 0.5837153325955959\n",
      "Step 237, Loss: 0.5834449838801317\n",
      "Step 238, Loss: 0.5831754544318899\n",
      "Step 239, Loss: 0.5829067389621934\n",
      "Step 240, Loss: 0.5826388322286473\n",
      "Step 241, Loss: 0.5823717290346735\n",
      "Step 242, Loss: 0.5821054242290467\n",
      "Step 243, Loss: 0.5818399127054394\n",
      "Step 244, Loss: 0.581575189401969\n",
      "Step 245, Loss: 0.5813112493007505\n",
      "Step 246, Loss: 0.5810480874274548\n",
      "Step 247, Loss: 0.5807856988508704\n",
      "Step 248, Loss: 0.580524078682472\n",
      "Step 249, Loss: 0.5802632220759908\n",
      "Step 250, Loss: 0.5800031242269923\n",
      "Step 251, Loss: 0.5797437803724564\n",
      "Step 252, Loss: 0.5794851857903643\n",
      "Step 253, Loss: 0.5792273357992871\n",
      "Step 254, Loss: 0.5789702257579815\n",
      "Step 255, Loss: 0.5787138510649882\n",
      "Step 256, Loss: 0.5784582071582355\n",
      "Step 257, Loss: 0.5782032895146463\n",
      "Step 258, Loss: 0.5779490936497502\n",
      "Step 259, Loss: 0.5776956151173\n",
      "Step 260, Loss: 0.5774428495088906\n",
      "Step 261, Loss: 0.5771907924535838\n",
      "Step 262, Loss: 0.5769394396175372\n",
      "Step 263, Loss: 0.5766887867036352\n",
      "Step 264, Loss: 0.5764388294511262\n",
      "Step 265, Loss: 0.5761895636352623\n",
      "Step 266, Loss: 0.5759409850669431\n",
      "Step 267, Loss: 0.5756930895923645\n",
      "Step 268, Loss: 0.575445873092669\n",
      "Step 269, Loss: 0.575199331483602\n",
      "Step 270, Loss: 0.5749534607151706\n",
      "Step 271, Loss: 0.5747082567713064\n",
      "Step 272, Loss: 0.5744637156695317\n",
      "Step 273, Loss: 0.5742198334606299\n",
      "Step 274, Loss: 0.5739766062283183\n",
      "Step 275, Loss: 0.5737340300889253\n",
      "Step 276, Loss: 0.573492101191072\n",
      "Step 277, Loss: 0.5732508157153541\n",
      "Step 278, Loss: 0.5730101698740308\n",
      "Step 279, Loss: 0.5727701599107147\n",
      "Step 280, Loss: 0.5725307821000657\n",
      "Step 281, Loss: 0.5722920327474889\n",
      "Step 282, Loss: 0.5720539081888341\n",
      "Step 283, Loss: 0.5718164047900999\n",
      "Step 284, Loss: 0.5715795189471409\n",
      "Step 285, Loss: 0.5713432470853774\n",
      "Step 286, Loss: 0.5711075856595079\n",
      "Step 287, Loss: 0.5708725311532262\n",
      "Step 288, Loss: 0.5706380800789397\n",
      "Step 289, Loss: 0.570404228977492\n",
      "Step 290, Loss: 0.570170974417888\n",
      "Step 291, Loss: 0.5699383129970219\n",
      "Step 292, Loss: 0.5697062413394076\n",
      "Step 293, Loss: 0.5694747560969138\n",
      "Step 294, Loss: 0.5692438539484987\n",
      "Step 295, Loss: 0.5690135315999516\n",
      "Step 296, Loss: 0.5687837857836333\n",
      "Step 297, Loss: 0.568554613258222\n",
      "Step 298, Loss: 0.5683260108084603\n",
      "Step 299, Loss: 0.5680979752449065\n",
      "Step 300, Loss: 0.5678705034036862\n",
      "Step 301, Loss: 0.5676435921462488\n",
      "Step 302, Loss: 0.5674172383591258\n",
      "Step 303, Loss: 0.5671914389536911\n",
      "Step 304, Loss: 0.5669661908659235\n",
      "Step 305, Loss: 0.5667414910561742\n",
      "Step 306, Loss: 0.5665173365089339\n",
      "Step 307, Loss: 0.566293724232603\n",
      "Step 308, Loss: 0.566070651259266\n",
      "Step 309, Loss: 0.565848114644466\n",
      "Step 310, Loss: 0.5656261114669829\n",
      "Step 311, Loss: 0.5654046388286134\n",
      "Step 312, Loss: 0.5651836938539535\n",
      "Step 313, Loss: 0.564963273690184\n",
      "Step 314, Loss: 0.5647433755068559\n",
      "Step 315, Loss: 0.5645239964956816\n",
      "Step 316, Loss: 0.5643051338703249\n",
      "Step 317, Loss: 0.5640867848661955\n",
      "Step 318, Loss: 0.5638689467402443\n",
      "Step 319, Loss: 0.5636516167707618\n",
      "Step 320, Loss: 0.5634347922571781\n",
      "Step 321, Loss: 0.5632184705198646\n",
      "Step 322, Loss: 0.563002648899939\n",
      "Step 323, Loss: 0.562787324759071\n",
      "Step 324, Loss: 0.5625724954792907\n",
      "Step 325, Loss: 0.5623581584627991\n",
      "Step 326, Loss: 0.5621443111317802\n",
      "Step 327, Loss: 0.5619309509282152\n",
      "Step 328, Loss: 0.561718075313699\n",
      "Step 329, Loss: 0.5615056817692575\n",
      "Step 330, Loss: 0.5612937677951685\n",
      "Step 331, Loss: 0.561082330910783\n",
      "Step 332, Loss: 0.5608713686543487\n",
      "Step 333, Loss: 0.5606608785828362\n",
      "Step 334, Loss: 0.5604508582717653\n",
      "Step 335, Loss: 0.5602413053150352\n",
      "Step 336, Loss: 0.5600322173247545\n",
      "Step 337, Loss: 0.5598235919310742\n",
      "Step 338, Loss: 0.5596154267820218\n",
      "Step 339, Loss: 0.5594077195433377\n",
      "Step 340, Loss: 0.5592004678983129\n",
      "Step 341, Loss: 0.5589936695476277\n",
      "Step 342, Loss: 0.5587873222091937\n",
      "Step 343, Loss: 0.5585814236179962\n",
      "Step 344, Loss: 0.5583759715259377\n",
      "Step 345, Loss: 0.5581709637016854\n",
      "Step 346, Loss: 0.557966397930517\n",
      "Step 347, Loss: 0.5577622720141712\n",
      "Step 348, Loss: 0.5575585837706968\n",
      "Step 349, Loss: 0.5573553310343063\n",
      "Step 350, Loss: 0.5571525116552289\n",
      "Step 351, Loss: 0.5569501234995651\n",
      "Step 352, Loss: 0.5567481644491439\n",
      "Step 353, Loss: 0.556546632401381\n",
      "Step 354, Loss: 0.556345525269138\n",
      "Step 355, Loss: 0.5561448409805836\n",
      "Step 356, Loss: 0.5559445774790552\n",
      "Step 357, Loss: 0.5557447327229241\n",
      "Step 358, Loss: 0.5555453046854587\n",
      "Step 359, Loss: 0.5553462913546932\n",
      "Step 360, Loss: 0.5551476907332936\n",
      "Step 361, Loss: 0.554949500838428\n",
      "Step 362, Loss: 0.5547517197016365\n",
      "Step 363, Loss: 0.5545543453687036\n",
      "Step 364, Loss: 0.5543573758995308\n",
      "Step 365, Loss: 0.5541608093680115\n",
      "Step 366, Loss: 0.5539646438619062\n",
      "Step 367, Loss: 0.5537688774827197\n",
      "Step 368, Loss: 0.5535735083455793\n",
      "Step 369, Loss: 0.5533785345791138\n",
      "Step 370, Loss: 0.5531839543253346\n",
      "Step 371, Loss: 0.5529897657395176\n",
      "Step 372, Loss: 0.5527959669900857\n",
      "Step 373, Loss: 0.5526025562584929\n",
      "Step 374, Loss: 0.5524095317391101\n",
      "Step 375, Loss: 0.5522168916391113\n",
      "Step 376, Loss: 0.5520246341783611\n",
      "Step 377, Loss: 0.5518327575893043\n",
      "Step 378, Loss: 0.5516412601168539\n",
      "Step 379, Loss: 0.5514501400182841\n",
      "Step 380, Loss: 0.5512593955631206\n",
      "Step 381, Loss: 0.5510690250330352\n",
      "Step 382, Loss: 0.5508790267217387\n",
      "Step 383, Loss: 0.550689398934877\n",
      "Step 384, Loss: 0.5505001399899264\n",
      "Step 385, Loss: 0.550311248216092\n",
      "Step 386, Loss: 0.5501227219542054\n",
      "Step 387, Loss: 0.5499345595566237\n",
      "Step 388, Loss: 0.5497467593871306\n",
      "Step 389, Loss: 0.5495593198208372\n",
      "Step 390, Loss: 0.5493722392440835\n",
      "Step 391, Loss: 0.5491855160543435\n",
      "Step 392, Loss: 0.5489991486601277\n",
      "Step 393, Loss: 0.5488131354808888\n",
      "Step 394, Loss: 0.548627474946928\n",
      "Step 395, Loss: 0.5484421654993014\n",
      "Step 396, Loss: 0.5482572055897285\n",
      "Step 397, Loss: 0.5480725936805004\n",
      "Step 398, Loss: 0.5478883282443903\n",
      "Step 399, Loss: 0.5477044077645629\n",
      "Step 400, Loss: 0.5475208307344869\n",
      "Step 401, Loss: 0.5473375956578467\n",
      "Step 402, Loss: 0.5471547010484559\n",
      "Step 403, Loss: 0.546972145430171\n",
      "Step 404, Loss: 0.5467899273368065\n",
      "Step 405, Loss: 0.5466080453120506\n",
      "Step 406, Loss: 0.5464264979093814\n",
      "Step 407, Loss: 0.5462452836919842\n",
      "Step 408, Loss: 0.5460644012326703\n",
      "Step 409, Loss: 0.5458838491137948\n",
      "Step 410, Loss: 0.5457036259271775\n",
      "Step 411, Loss: 0.545523730274022\n",
      "Step 412, Loss: 0.5453441607648383\n",
      "Step 413, Loss: 0.5451649160193639\n",
      "Step 414, Loss: 0.5449859946664868\n",
      "Step 415, Loss: 0.5448073953441688\n",
      "Step 416, Loss: 0.5446291166993704\n",
      "Step 417, Loss: 0.5444511573879751\n",
      "Step 418, Loss: 0.5442735160747151\n",
      "Step 419, Loss: 0.5440961914330976\n",
      "Step 420, Loss: 0.5439191821453327\n",
      "Step 421, Loss: 0.5437424869022605\n",
      "Step 422, Loss: 0.5435661044032795\n",
      "Step 423, Loss: 0.5433900333562759\n",
      "Step 424, Loss: 0.5432142724775539\n",
      "Step 425, Loss: 0.5430388204917658\n",
      "Step 426, Loss: 0.5428636761318428\n",
      "Step 427, Loss: 0.5426888381389278\n",
      "Step 428, Loss: 0.5425143052623069\n",
      "Step 429, Loss: 0.5423400762593433\n",
      "Step 430, Loss: 0.5421661498954108\n",
      "Step 431, Loss: 0.5419925249438273\n",
      "Step 432, Loss: 0.5418192001857918\n",
      "Step 433, Loss: 0.5416461744103181\n",
      "Step 434, Loss: 0.5414734464141719\n",
      "Step 435, Loss: 0.5413010150018077\n",
      "Step 436, Loss: 0.5411288789853057\n",
      "Step 437, Loss: 0.5409570371843105\n",
      "Step 438, Loss: 0.5407854884259693\n",
      "Step 439, Loss: 0.5406142315448712\n",
      "Step 440, Loss: 0.5404432653829865\n",
      "Step 441, Loss: 0.540272588789608\n",
      "Step 442, Loss: 0.5401022006212912\n",
      "Step 443, Loss: 0.5399320997417957\n",
      "Step 444, Loss: 0.5397622850220272\n",
      "Step 445, Loss: 0.5395927553399804\n",
      "Step 446, Loss: 0.5394235095806819\n",
      "Step 447, Loss: 0.5392545466361336\n",
      "Step 448, Loss: 0.5390858654052567\n",
      "Step 449, Loss: 0.5389174647938372\n",
      "Step 450, Loss: 0.5387493437144697\n",
      "Step 451, Loss: 0.5385815010865045\n",
      "Step 452, Loss: 0.5384139358359924\n",
      "Step 453, Loss: 0.5382466468956327\n",
      "Step 454, Loss: 0.5380796332047195\n",
      "Step 455, Loss: 0.5379128937090891\n",
      "Step 456, Loss: 0.5377464273610695\n",
      "Step 457, Loss: 0.5375802331194273\n",
      "Step 458, Loss: 0.537414309949318\n",
      "Step 459, Loss: 0.5372486568222352\n",
      "Step 460, Loss: 0.5370832727159606\n",
      "Step 461, Loss: 0.5369181566145144\n",
      "Step 462, Loss: 0.5367533075081063\n",
      "Step 463, Loss: 0.5365887243930871\n",
      "Step 464, Loss: 0.5364244062719002\n",
      "Step 465, Loss: 0.5362603521530342\n",
      "Step 466, Loss: 0.5360965610509754\n",
      "Step 467, Loss: 0.5359330319861609\n",
      "Step 468, Loss: 0.5357697639849325\n",
      "Step 469, Loss: 0.5356067560794899\n",
      "Step 470, Loss: 0.5354440073078468\n",
      "Step 471, Loss: 0.5352815167137838\n",
      "Step 472, Loss: 0.5351192833468044\n",
      "Step 473, Loss: 0.5349573062620913\n",
      "Step 474, Loss: 0.5347955845204613\n",
      "Step 475, Loss: 0.5346341171883231\n",
      "Step 476, Loss: 0.5344729033376326\n",
      "Step 477, Loss: 0.5343119420458515\n",
      "Step 478, Loss: 0.5341512323959041\n",
      "Step 479, Loss: 0.5339907734761355\n",
      "Step 480, Loss: 0.5338305643802702\n",
      "Step 481, Loss: 0.5336706042073706\n",
      "Step 482, Loss: 0.5335108920617964\n",
      "Step 483, Loss: 0.5333514270531639\n",
      "Step 484, Loss: 0.5331922082963058\n",
      "Step 485, Loss: 0.5330332349112317\n",
      "Step 486, Loss: 0.5328745060230881\n",
      "Step 487, Loss: 0.5327160207621203\n",
      "Step 488, Loss: 0.5325577782636329\n",
      "Step 489, Loss: 0.5323997776679518\n",
      "Step 490, Loss: 0.5322420181203856\n",
      "Step 491, Loss: 0.5320844987711888\n",
      "Step 492, Loss: 0.5319272187755241\n",
      "Step 493, Loss: 0.5317701772934245\n",
      "Step 494, Loss: 0.5316133734897582\n",
      "Step 495, Loss: 0.5314568065341911\n",
      "Step 496, Loss: 0.531300475601151\n",
      "Step 497, Loss: 0.5311443798697921\n",
      "Step 498, Loss: 0.5309885185239593\n",
      "Step 499, Loss: 0.5308328907521535\n",
      "Step 500, Loss: 0.530677495747496\n",
      "Step 501, Loss: 0.5305223327076956\n",
      "Step 502, Loss: 0.530367400835012\n",
      "Step 503, Loss: 0.5302126993362247\n",
      "Step 504, Loss: 0.5300582274225972\n",
      "Step 505, Loss: 0.5299039843098449\n",
      "Step 506, Loss: 0.5297499692181018\n",
      "Step 507, Loss: 0.5295961813718878\n",
      "Step 508, Loss: 0.529442620000076\n",
      "Step 509, Loss: 0.5292892843358614\n",
      "Step 510, Loss: 0.5291361736167279\n",
      "Step 511, Loss: 0.528983287084418\n",
      "Step 512, Loss: 0.5288306239849\n",
      "Step 513, Loss: 0.5286781835683386\n",
      "Step 514, Loss: 0.5285259650890629\n",
      "Step 515, Loss: 0.5283739678055367\n",
      "Step 516, Loss: 0.5282221909803276\n",
      "Step 517, Loss: 0.5280706338800778\n",
      "Step 518, Loss: 0.5279192957754737\n",
      "Step 519, Loss: 0.5277681759412168\n",
      "Step 520, Loss: 0.5276172736559946\n",
      "Step 521, Loss: 0.5274665882024515\n",
      "Step 522, Loss: 0.5273161188671601\n",
      "Step 523, Loss: 0.5271658649405928\n",
      "Step 524, Loss: 0.5270158257170937\n",
      "Step 525, Loss: 0.5268660004948504\n",
      "Step 526, Loss: 0.526716388575867\n",
      "Step 527, Loss: 0.5265669892659351\n",
      "Step 528, Loss: 0.5264178018746086\n",
      "Step 529, Loss: 0.526268825715175\n",
      "Step 530, Loss: 0.5261200601046292\n",
      "Step 531, Loss: 0.5259715043636475\n",
      "Step 532, Loss: 0.5258231578165604\n",
      "Step 533, Loss: 0.5256750197913272\n",
      "Step 534, Loss: 0.5255270896195097\n",
      "Step 535, Loss: 0.5253793666362463\n",
      "Step 536, Loss: 0.5252318501802277\n",
      "Step 537, Loss: 0.5250845395936704\n",
      "Step 538, Loss: 0.5249374342222923\n",
      "Step 539, Loss: 0.524790533415288\n",
      "Step 540, Loss: 0.524643836525304\n",
      "Step 541, Loss: 0.5244973429084141\n",
      "Step 542, Loss: 0.5243510519240958\n",
      "Step 543, Loss: 0.5242049629352058\n",
      "Step 544, Loss: 0.5240590753079569\n",
      "Step 545, Loss: 0.5239133884118935\n",
      "Step 546, Loss: 0.5237679016198691\n",
      "Step 547, Loss: 0.5236226143080224\n",
      "Step 548, Loss: 0.5234775258557548\n",
      "Step 549, Loss: 0.5233326356457079\n",
      "Step 550, Loss: 0.5231879430637401\n",
      "Step 551, Loss: 0.5230434474989045\n",
      "Step 552, Loss: 0.5228991483434273\n",
      "Step 553, Loss: 0.5227550449926847\n",
      "Step 554, Loss: 0.5226111368451821\n",
      "Step 555, Loss: 0.5224674233025315\n",
      "Step 556, Loss: 0.5223239037694306\n",
      "Step 557, Loss: 0.5221805776536416\n",
      "Step 558, Loss: 0.5220374443659692\n",
      "Step 559, Loss: 0.5218945033202411\n",
      "Step 560, Loss: 0.5217517539332857\n",
      "Step 561, Loss: 0.5216091956249123\n",
      "Step 562, Loss: 0.5214668278178907\n",
      "Step 563, Loss: 0.5213246499379304\n",
      "Step 564, Loss: 0.5211826614136612\n",
      "Step 565, Loss: 0.5210408616766127\n",
      "Step 566, Loss: 0.5208992501611946\n",
      "Step 567, Loss: 0.5207578263046779\n",
      "Step 568, Loss: 0.5206165895471735\n",
      "Step 569, Loss: 0.5204755393316151\n",
      "Step 570, Loss: 0.5203346751037388\n",
      "Step 571, Loss: 0.5201939963120645\n",
      "Step 572, Loss: 0.520053502407877\n",
      "Step 573, Loss: 0.5199131928452073\n",
      "Step 574, Loss: 0.519773067080814\n",
      "Step 575, Loss: 0.5196331245741653\n",
      "Step 576, Loss: 0.5194933647874205\n",
      "Step 577, Loss: 0.5193537871854115\n",
      "Step 578, Loss: 0.5192143912356257\n",
      "Step 579, Loss: 0.5190751764081881\n",
      "Step 580, Loss: 0.5189361421758429\n",
      "Step 581, Loss: 0.5187972880139365\n",
      "Step 582, Loss: 0.5186586134004006\n",
      "Step 583, Loss: 0.5185201178157343\n",
      "Step 584, Loss: 0.518381800742987\n",
      "Step 585, Loss: 0.5182436616677425\n",
      "Step 586, Loss: 0.5181057000781004\n",
      "Step 587, Loss: 0.5179679154646613\n",
      "Step 588, Loss: 0.5178303073205088\n",
      "Step 589, Loss: 0.5176928751411946\n",
      "Step 590, Loss: 0.5175556184247201\n",
      "Step 591, Loss: 0.5174185366715227\n",
      "Step 592, Loss: 0.5172816293844582\n",
      "Step 593, Loss: 0.5171448960687848\n",
      "Step 594, Loss: 0.5170083362321485\n",
      "Step 595, Loss: 0.5168719493845668\n",
      "Step 596, Loss: 0.516735735038413\n",
      "Step 597, Loss: 0.5165996927084009\n",
      "Step 598, Loss: 0.5164638219115704\n",
      "Step 599, Loss: 0.5163281221672706\n",
      "Step 600, Loss: 0.5161925929971468\n",
      "Step 601, Loss: 0.5160572339251239\n",
      "Step 602, Loss: 0.5159220444773929\n",
      "Step 603, Loss: 0.515787024182395\n",
      "Step 604, Loss: 0.5156521725708083\n",
      "Step 605, Loss: 0.5155174891755328\n",
      "Step 606, Loss: 0.5153829735316753\n",
      "Step 607, Loss: 0.5152486251765367\n",
      "Step 608, Loss: 0.5151144436495968\n",
      "Step 609, Loss: 0.5149804284925008\n",
      "Step 610, Loss: 0.514846579249045\n",
      "Step 611, Loss: 0.5147128954651636\n",
      "Step 612, Loss: 0.5145793766889144\n",
      "Step 613, Loss: 0.5144460224704657\n",
      "Step 614, Loss: 0.5143128323620827\n",
      "Step 615, Loss: 0.5141798059181144\n",
      "Step 616, Loss: 0.5140469426949796\n",
      "Step 617, Loss: 0.5139142422511543\n",
      "Step 618, Loss: 0.5137817041471594\n",
      "Step 619, Loss: 0.5136493279455461\n",
      "Step 620, Loss: 0.5135171132108842\n",
      "Step 621, Loss: 0.5133850595097493\n",
      "Step 622, Loss: 0.5132531664107097\n",
      "Step 623, Loss: 0.5131214334843144\n",
      "Step 624, Loss: 0.5129898603030799\n",
      "Step 625, Loss: 0.5128584464414787\n",
      "Step 626, Loss: 0.5127271914759266\n",
      "Step 627, Loss: 0.5125960949847705\n",
      "Step 628, Loss: 0.5124651565482763\n",
      "Step 629, Loss: 0.5123343757486174\n",
      "Step 630, Loss: 0.5122037521698617\n",
      "Step 631, Loss: 0.5120732853979616\n",
      "Step 632, Loss: 0.5119429750207403\n",
      "Step 633, Loss: 0.5118128206278817\n",
      "Step 634, Loss: 0.5116828218109181\n",
      "Step 635, Loss: 0.5115529781632187\n",
      "Step 636, Loss: 0.5114232892799789\n",
      "Step 637, Loss: 0.5112937547582084\n",
      "Step 638, Loss: 0.5111643741967205\n",
      "Step 639, Loss: 0.5110351471961203\n",
      "Step 640, Loss: 0.5109060733587943\n",
      "Step 641, Loss: 0.5107771522888997\n",
      "Step 642, Loss: 0.5106483835923525\n",
      "Step 643, Loss: 0.5105197668768178\n",
      "Step 644, Loss: 0.5103913017516986\n",
      "Step 645, Loss: 0.510262987828125\n",
      "Step 646, Loss: 0.5101348247189444\n",
      "Step 647, Loss: 0.5100068120387105\n",
      "Step 648, Loss: 0.5098789494036726\n",
      "Step 649, Loss: 0.5097512364317665\n",
      "Step 650, Loss: 0.5096236727426028\n",
      "Step 651, Loss: 0.5094962579574578\n",
      "Step 652, Loss: 0.5093689916992632\n",
      "Step 653, Loss: 0.5092418735925959\n",
      "Step 654, Loss: 0.5091149032636683\n",
      "Step 655, Loss: 0.5089880803403182\n",
      "Step 656, Loss: 0.5088614044519992\n",
      "Step 657, Loss: 0.5087348752297718\n",
      "Step 658, Loss: 0.5086084923062916\n",
      "Step 659, Loss: 0.5084822553158019\n",
      "Step 660, Loss: 0.508356163894124\n",
      "Step 661, Loss: 0.508230217678646\n",
      "Step 662, Loss: 0.5081044163083155\n",
      "Step 663, Loss: 0.5079787594236295\n",
      "Step 664, Loss: 0.5078532466666248\n",
      "Step 665, Loss: 0.5077278776808697\n",
      "Step 666, Loss: 0.5076026521114543\n",
      "Step 667, Loss: 0.5074775696049815\n",
      "Step 668, Loss: 0.5073526298095585\n",
      "Step 669, Loss: 0.5072278323747877\n",
      "Step 670, Loss: 0.5071031769517578\n",
      "Step 671, Loss: 0.5069786631930351\n",
      "Step 672, Loss: 0.5068542907526545\n",
      "Step 673, Loss: 0.506730059286112\n",
      "Step 674, Loss: 0.5066059684503548\n",
      "Step 675, Loss: 0.5064820179037731\n",
      "Step 676, Loss: 0.5063582073061929\n",
      "Step 677, Loss: 0.5062345363188654\n",
      "Step 678, Loss: 0.5061110046044611\n",
      "Step 679, Loss: 0.5059876118270596\n",
      "Step 680, Loss: 0.5058643576521427\n",
      "Step 681, Loss: 0.5057412417465853\n",
      "Step 682, Loss: 0.5056182637786483\n",
      "Step 683, Loss: 0.5054954234179698\n",
      "Step 684, Loss: 0.5053727203355575\n",
      "Step 685, Loss: 0.5052501542037804\n",
      "Step 686, Loss: 0.5051277246963618\n",
      "Step 687, Loss: 0.5050054314883707\n",
      "Step 688, Loss: 0.5048832742562143\n",
      "Step 689, Loss: 0.5047612526776304\n",
      "Step 690, Loss: 0.5046393664316797\n",
      "Step 691, Loss: 0.5045176151987387\n",
      "Step 692, Loss: 0.5043959986604911\n",
      "Step 693, Loss: 0.5042745164999214\n",
      "Step 694, Loss: 0.504153168401307\n",
      "Step 695, Loss: 0.5040319540502107\n",
      "Step 696, Loss: 0.5039108731334743\n",
      "Step 697, Loss: 0.5037899253392097\n",
      "Step 698, Loss: 0.5036691103567936\n",
      "Step 699, Loss: 0.5035484278768588\n",
      "Step 700, Loss: 0.5034278775912879\n",
      "Step 701, Loss: 0.5033074591932062\n",
      "Step 702, Loss: 0.5031871723769743\n",
      "Step 703, Loss: 0.5030670168381814\n",
      "Step 704, Loss: 0.5029469922736389\n",
      "Step 705, Loss: 0.5028270983813725\n",
      "Step 706, Loss: 0.5027073348606161\n",
      "Step 707, Loss: 0.502587701411805\n",
      "Step 708, Loss: 0.5024681977365688\n",
      "Step 709, Loss: 0.5023488235377255\n",
      "Step 710, Loss: 0.5022295785192739\n",
      "Step 711, Loss: 0.5021104623863875\n",
      "Step 712, Loss: 0.5019914748454084\n",
      "Step 713, Loss: 0.50187261560384\n",
      "Step 714, Loss: 0.5017538843703412\n",
      "Step 715, Loss: 0.5016352808547199\n",
      "Step 716, Loss: 0.5015168047679256\n",
      "Step 717, Loss: 0.5013984558220453\n",
      "Step 718, Loss: 0.5012802337302954\n",
      "Step 719, Loss: 0.5011621382070156\n",
      "Step 720, Loss: 0.5010441689676638\n",
      "Step 721, Loss: 0.5009263257288088\n",
      "Step 722, Loss: 0.5008086082081251\n",
      "Step 723, Loss: 0.5006910161243865\n",
      "Step 724, Loss: 0.5005735491974598\n",
      "Step 725, Loss: 0.5004562071482992\n",
      "Step 726, Loss: 0.5003389896989402\n",
      "Step 727, Loss: 0.5002218965724942\n",
      "Step 728, Loss: 0.5001049274931417\n",
      "Step 729, Loss: 0.49998808218612734\n",
      "Step 730, Loss: 0.4998713603777537\n",
      "Step 731, Loss: 0.49975476179537603\n",
      "Step 732, Loss: 0.4996382861673954\n",
      "Step 733, Loss: 0.49952193322325494\n",
      "Step 734, Loss: 0.49940570269343265\n",
      "Step 735, Loss: 0.49928959430943626\n",
      "Step 736, Loss: 0.49917360780379766\n",
      "Step 737, Loss: 0.49905774291006805\n",
      "Step 738, Loss: 0.49894199936281164\n",
      "Step 739, Loss: 0.49882637689760045\n",
      "Step 740, Loss: 0.498710875251009\n",
      "Step 741, Loss: 0.49859549416060933\n",
      "Step 742, Loss: 0.49848023336496466\n",
      "Step 743, Loss: 0.4983650926036255\n",
      "Step 744, Loss: 0.498250071617123\n",
      "Step 745, Loss: 0.4981351701469648\n",
      "Step 746, Loss: 0.49802038793562947\n",
      "Step 747, Loss: 0.49790572472656114\n",
      "Step 748, Loss: 0.49779118026416463\n",
      "Step 749, Loss: 0.49767675429380065\n",
      "Step 750, Loss: 0.49756244656177995\n",
      "Step 751, Loss: 0.4974482568153594\n",
      "Step 752, Loss: 0.497334184802736\n",
      "Step 753, Loss: 0.4972202302730425\n",
      "Step 754, Loss: 0.4971063929763426\n",
      "Step 755, Loss: 0.49699267266362546\n",
      "Step 756, Loss: 0.4968790690868016\n",
      "Step 757, Loss: 0.4967655819986973\n",
      "Step 758, Loss: 0.49665221115305086\n",
      "Step 759, Loss: 0.4965389563045067\n",
      "Step 760, Loss: 0.4964258172086115\n",
      "Step 761, Loss: 0.49631279362180897\n",
      "Step 762, Loss: 0.4961998853014357\n",
      "Step 763, Loss: 0.49608709200571594\n",
      "Step 764, Loss: 0.4959744134937577\n",
      "Step 765, Loss: 0.49586184952554735\n",
      "Step 766, Loss: 0.4957493998619459\n",
      "Step 767, Loss: 0.495637064264684\n",
      "Step 768, Loss: 0.4955248424963575\n",
      "Step 769, Loss: 0.4954127343204234\n",
      "Step 770, Loss: 0.4953007395011948\n",
      "Step 771, Loss: 0.4951888578038369\n",
      "Step 772, Loss: 0.49507708899436303\n",
      "Step 773, Loss: 0.49496543283962896\n",
      "Step 774, Loss: 0.4948538891073303\n",
      "Step 775, Loss: 0.4947424575659972\n",
      "Step 776, Loss: 0.49463113798499025\n",
      "Step 777, Loss: 0.4945199301344962\n",
      "Step 778, Loss: 0.49440883378552397\n",
      "Step 779, Loss: 0.49429784870990073\n",
      "Step 780, Loss: 0.49418697468026684\n",
      "Step 781, Loss: 0.494076211470073\n",
      "Step 782, Loss: 0.49396555885357474\n",
      "Step 783, Loss: 0.49385501660582964\n",
      "Step 784, Loss: 0.49374458450269254\n",
      "Step 785, Loss: 0.493634262320812\n",
      "Step 786, Loss: 0.49352404983762527\n",
      "Step 787, Loss: 0.49341394683135614\n",
      "Step 788, Loss: 0.49330395308100944\n",
      "Step 789, Loss: 0.4931940683663676\n",
      "Step 790, Loss: 0.4930842924679869\n",
      "Step 791, Loss: 0.49297462516719365\n",
      "Step 792, Loss: 0.4928650662460802\n",
      "Step 793, Loss: 0.49275561548750113\n",
      "Step 794, Loss: 0.49264627267506944\n",
      "Step 795, Loss: 0.49253703759315287\n",
      "Step 796, Loss: 0.4924279100268699\n",
      "Step 797, Loss: 0.492318889762087\n",
      "Step 798, Loss: 0.4922099765854133\n",
      "Step 799, Loss: 0.49210117028419836\n",
      "Step 800, Loss: 0.4919924706465276\n",
      "Step 801, Loss: 0.4918838774612196\n",
      "Step 802, Loss: 0.49177539051782126\n",
      "Step 803, Loss: 0.4916670096066055\n",
      "Step 804, Loss: 0.4915587345185665\n",
      "Step 805, Loss: 0.4914505650454174\n",
      "Step 806, Loss: 0.49134250097958576\n",
      "Step 807, Loss: 0.49123454211421047\n",
      "Step 808, Loss: 0.49112668824313843\n",
      "Step 809, Loss: 0.4910189391609208\n",
      "Step 810, Loss: 0.4909112946628097\n",
      "Step 811, Loss: 0.49080375454475506\n",
      "Step 812, Loss: 0.4906963186034005\n",
      "Step 813, Loss: 0.4905889866360811\n",
      "Step 814, Loss: 0.4904817584408187\n",
      "Step 815, Loss: 0.4903746338163197\n",
      "Step 816, Loss: 0.49026761256197143\n",
      "Step 817, Loss: 0.49016069447783844\n",
      "Step 818, Loss: 0.49005387936465983\n",
      "Step 819, Loss: 0.4899471670238455\n",
      "Step 820, Loss: 0.48984055725747344\n",
      "Step 821, Loss: 0.4897340498682861\n",
      "Step 822, Loss: 0.48962764465968744\n",
      "Step 823, Loss: 0.48952134143573955\n",
      "Step 824, Loss: 0.4894151400011598\n",
      "Step 825, Loss: 0.48930904016131754\n",
      "Step 826, Loss: 0.489203041722231\n",
      "Step 827, Loss: 0.4890971444905639\n",
      "Step 828, Loss: 0.48899134827362334\n",
      "Step 829, Loss: 0.48888565287935537\n",
      "Step 830, Loss: 0.48878005811634323\n",
      "Step 831, Loss: 0.4886745637938036\n",
      "Step 832, Loss: 0.48856916972158365\n",
      "Step 833, Loss: 0.4884638757101586\n",
      "Step 834, Loss: 0.4883586815706278\n",
      "Step 835, Loss: 0.48825358711471284\n",
      "Step 836, Loss: 0.4881485921547538\n",
      "Step 837, Loss: 0.4880436965037068\n",
      "Step 838, Loss: 0.48793889997514145\n",
      "Step 839, Loss: 0.48783420238323655\n",
      "Step 840, Loss: 0.4877296035427787\n",
      "Step 841, Loss: 0.4876251032691593\n",
      "Step 842, Loss: 0.4875207013783709\n",
      "Step 843, Loss: 0.487416397687005\n",
      "Step 844, Loss: 0.4873121920122491\n",
      "Step 845, Loss: 0.48720808417188427\n",
      "Step 846, Loss: 0.4871040739842817\n",
      "Step 847, Loss: 0.4870001612684005\n",
      "Step 848, Loss: 0.48689634584378483\n",
      "Step 849, Loss: 0.48679262753056135\n",
      "Step 850, Loss: 0.48668900614943594\n",
      "Step 851, Loss: 0.486585481521692\n",
      "Step 852, Loss: 0.48648205346918694\n",
      "Step 853, Loss: 0.4863787218143497\n",
      "Step 854, Loss: 0.48627548638017865\n",
      "Step 855, Loss: 0.48617234699023815\n",
      "Step 856, Loss: 0.48606930346865695\n",
      "Step 857, Loss: 0.48596635564012425\n",
      "Step 858, Loss: 0.48586350332988903\n",
      "Step 859, Loss: 0.4857607463637551\n",
      "Step 860, Loss: 0.485658084568081\n",
      "Step 861, Loss: 0.4855555177697758\n",
      "Step 862, Loss: 0.48545304579629694\n",
      "Step 863, Loss: 0.4853506684756484\n",
      "Step 864, Loss: 0.4852483856363774\n",
      "Step 865, Loss: 0.4851461971075725\n",
      "Step 866, Loss: 0.48504410271886067\n",
      "Step 867, Loss: 0.4849421023004055\n",
      "Step 868, Loss: 0.4848401956829041\n",
      "Step 869, Loss: 0.48473838269758496\n",
      "Step 870, Loss: 0.48463666317620574\n",
      "Step 871, Loss: 0.48453503695105055\n",
      "Step 872, Loss: 0.484433503854928\n",
      "Step 873, Loss: 0.48433206372116844\n",
      "Step 874, Loss: 0.48423071638362175\n",
      "Step 875, Loss: 0.4841294616766552\n",
      "Step 876, Loss: 0.4840282994351509\n",
      "Step 877, Loss: 0.4839272294945035\n",
      "Step 878, Loss: 0.4838262516906181\n",
      "Step 879, Loss: 0.4837253658599079\n",
      "Step 880, Loss: 0.48362457183929175\n",
      "Step 881, Loss: 0.4835238694661922\n",
      "Step 882, Loss: 0.48342325857853313\n",
      "Step 883, Loss: 0.4833227390147375\n",
      "Step 884, Loss: 0.4832223106137249\n",
      "Step 885, Loss: 0.48312197321490996\n",
      "Step 886, Loss: 0.48302172665819976\n",
      "Step 887, Loss: 0.48292157078399145\n",
      "Step 888, Loss: 0.4828215054331707\n",
      "Step 889, Loss: 0.48272153044710897\n",
      "Step 890, Loss: 0.4826216456676617\n",
      "Step 891, Loss: 0.4825218509371661\n",
      "Step 892, Loss: 0.4824221460984388\n",
      "Step 893, Loss: 0.48232253099477446\n",
      "Step 894, Loss: 0.4822230054699427\n",
      "Step 895, Loss: 0.48212356936818673\n",
      "Step 896, Loss: 0.4820242225342213\n",
      "Step 897, Loss: 0.4819249648132301\n",
      "Step 898, Loss: 0.4818257960508639\n",
      "Step 899, Loss: 0.48172671609323936\n",
      "Step 900, Loss: 0.48162772478693566\n",
      "Step 901, Loss: 0.48152882197899327\n",
      "Step 902, Loss: 0.4814300075169119\n",
      "Step 903, Loss: 0.4813312812486486\n",
      "Step 904, Loss: 0.48123264302261537\n",
      "Step 905, Loss: 0.4811340926876775\n",
      "Step 906, Loss: 0.4810356300931516\n",
      "Step 907, Loss: 0.4809372550888037\n",
      "Step 908, Loss: 0.48083896752484706\n",
      "Step 909, Loss: 0.4807407672519407\n",
      "Step 910, Loss: 0.48064265412118684\n",
      "Step 911, Loss: 0.4805446279841298\n",
      "Step 912, Loss: 0.4804466886927533\n",
      "Step 913, Loss: 0.4803488360994793\n",
      "Step 914, Loss: 0.4802510700571655\n",
      "Step 915, Loss: 0.48015339041910393\n",
      "Step 916, Loss: 0.480055797039019\n",
      "Step 917, Loss: 0.4799582897710657\n",
      "Step 918, Loss: 0.4798608684698271\n",
      "Step 919, Loss: 0.4797635329903141\n",
      "Step 920, Loss: 0.4796662831879616\n",
      "Step 921, Loss: 0.4795691189186286\n",
      "Step 922, Loss: 0.47947204003859484\n",
      "Step 923, Loss: 0.4793750464045602\n",
      "Step 924, Loss: 0.47927813787364243\n",
      "Step 925, Loss: 0.47918131430337496\n",
      "Step 926, Loss: 0.4790845755517063\n",
      "Step 927, Loss: 0.47898792147699715\n",
      "Step 928, Loss: 0.478891351938019\n",
      "Step 929, Loss: 0.47879486679395294\n",
      "Step 930, Loss: 0.4786984659043873\n",
      "Step 931, Loss: 0.47860214912931626\n",
      "Step 932, Loss: 0.4785059163291379\n",
      "Step 933, Loss: 0.4784097673646528\n",
      "Step 934, Loss: 0.47831370209706253\n",
      "Step 935, Loss: 0.4782177203879672\n",
      "Step 936, Loss: 0.47812182209936455\n",
      "Step 937, Loss: 0.47802600709364834\n",
      "Step 938, Loss: 0.47793027523360576\n",
      "Step 939, Loss: 0.47783462638241714\n",
      "Step 940, Loss: 0.47773906040365316\n",
      "Step 941, Loss: 0.4776435771612739\n",
      "Step 942, Loss: 0.4775481765196273\n",
      "Step 943, Loss: 0.4774528583434467\n",
      "Step 944, Loss: 0.4773576224978505\n",
      "Step 945, Loss: 0.47726246884833967\n",
      "Step 946, Loss: 0.47716739726079627\n",
      "Step 947, Loss: 0.4770724076014826\n",
      "Step 948, Loss: 0.47697749973703835\n",
      "Step 949, Loss: 0.47688267353448044\n",
      "Step 950, Loss: 0.4767879288612008\n",
      "Step 951, Loss: 0.4766932655849644\n",
      "Step 952, Loss: 0.47659868357390867\n",
      "Step 953, Loss: 0.4765041826965414\n",
      "Step 954, Loss: 0.4764097628217394\n",
      "Step 955, Loss: 0.4763154238187467\n",
      "Step 956, Loss: 0.4762211655571738\n",
      "Step 957, Loss: 0.47612698790699526\n",
      "Step 958, Loss: 0.4760328907385487\n",
      "Step 959, Loss: 0.4759388739225338\n",
      "Step 960, Loss: 0.47584493733000965\n",
      "Step 961, Loss: 0.47575108083239437\n",
      "Step 962, Loss: 0.47565730430146314\n",
      "Step 963, Loss: 0.4755636076093469\n",
      "Step 964, Loss: 0.475469990628531\n",
      "Step 965, Loss: 0.4753764532318538\n",
      "Step 966, Loss: 0.47528299529250473\n",
      "Step 967, Loss: 0.4751896166840236\n",
      "Step 968, Loss: 0.47509631728029894\n",
      "Step 969, Loss: 0.4750030969555662\n",
      "Step 970, Loss: 0.47490995558440724\n",
      "Step 971, Loss: 0.4748168930417478\n",
      "Step 972, Loss: 0.47472390920285734\n",
      "Step 973, Loss: 0.47463100394334673\n",
      "Step 974, Loss: 0.47453817713916724\n",
      "Step 975, Loss: 0.47444542866660966\n",
      "Step 976, Loss: 0.4743527584023017\n",
      "Step 977, Loss: 0.47426016622320805\n",
      "Step 978, Loss: 0.47416765200662814\n",
      "Step 979, Loss: 0.47407521563019533\n",
      "Step 980, Loss: 0.47398285697187503\n",
      "Step 981, Loss: 0.47389057590996436\n",
      "Step 982, Loss: 0.47379837232308936\n",
      "Step 983, Loss: 0.47370624609020523\n",
      "Step 984, Loss: 0.47361419709059405\n",
      "Step 985, Loss: 0.47352222520386383\n",
      "Step 986, Loss: 0.4734303303099473\n",
      "Step 987, Loss: 0.4733385122891004\n",
      "Step 988, Loss: 0.47324677102190116\n",
      "Step 989, Loss: 0.4731551063892484\n",
      "Step 990, Loss: 0.4730635182723608\n",
      "Step 991, Loss: 0.47297200655277505\n",
      "Step 992, Loss: 0.4728805711123451\n",
      "Step 993, Loss: 0.4727892118332406\n",
      "Step 994, Loss: 0.4726979285979457\n",
      "Step 995, Loss: 0.47260672128925824\n",
      "Step 996, Loss: 0.4725155897902882\n",
      "Step 997, Loss: 0.4724245339844563\n",
      "Step 998, Loss: 0.4723335537554932\n",
      "Step 999, Loss: 0.47224264898743806\n",
      "Accuracy: 0.85\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a homework try to solve the following problem with logistic regression: Given a dimension n, detect if n dimensional vector is located in n dimensional sphere with a radius equal to 1."
   ],
   "metadata": {
    "id": "dnZBmw4_RyO5"
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 11) (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_dataset(num_samples, dimension=10):\n",
    "    X = np.random.uniform(-1, 1, size=(num_samples, dimension))  # Generate random vectors in the range [-1, 1]\n",
    "    y = np.linalg.norm(X, axis=1) <= 1  # Determine whether the vectors lie inside the unit sphere\n",
    "    y = y.astype(int)  # Convert boolean labels to integers (0 or 1)\n",
    "    return X, y[:, np.newaxis]  # Ensure y has shape (num_samples, 1)\n",
    "\n",
    "# Generate dataset\n",
    "num_samples = 1000\n",
    "dimension = 10\n",
    "X, y = generate_dataset(num_samples, dimension)\n",
    "\n",
    "# Add intercept column to X (for bias)\n",
    "X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "print(X.shape, y.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T23:14:54.614432Z",
     "start_time": "2024-04-03T23:14:54.608136Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 0.6931471805599452\n",
      "Step 1, Loss: 0.6906669907988805\n",
      "Step 2, Loss: 0.688199320643258\n",
      "Step 3, Loss: 0.6857441066477051\n",
      "Step 4, Loss: 0.6833012855340865\n",
      "Step 5, Loss: 0.6808707941941973\n",
      "Step 6, Loss: 0.6784525696923934\n",
      "Step 7, Loss: 0.6760465492681653\n",
      "Step 8, Loss: 0.6736526703386458\n",
      "Step 9, Loss: 0.6712708705010633\n",
      "Step 10, Loss: 0.6689010875351332\n",
      "Step 11, Loss: 0.6665432594053904\n",
      "Step 12, Loss: 0.6641973242634661\n",
      "Step 13, Loss: 0.6618632204503051\n",
      "Step 14, Loss: 0.6595408864983267\n",
      "Step 15, Loss: 0.657230261133529\n",
      "Step 16, Loss: 0.6549312832775397\n",
      "Step 17, Loss: 0.6526438920496083\n",
      "Step 18, Loss: 0.6503680267685467\n",
      "Step 19, Loss: 0.6481036269546139\n",
      "Step 20, Loss: 0.6458506323313493\n",
      "Step 21, Loss: 0.6436089828273509\n",
      "Step 22, Loss: 0.6413786185780037\n",
      "Step 23, Loss: 0.6391594799271548\n",
      "Step 24, Loss: 0.6369515074287392\n",
      "Step 25, Loss: 0.6347546418483533\n",
      "Step 26, Loss: 0.6325688241647804\n",
      "Step 27, Loss: 0.6303939955714669\n",
      "Step 28, Loss: 0.6282300974779488\n",
      "Step 29, Loss: 0.6260770715112313\n",
      "Step 30, Loss: 0.6239348595171212\n",
      "Step 31, Loss: 0.6218034035615126\n",
      "Step 32, Loss: 0.6196826459316256\n",
      "Step 33, Loss: 0.6175725291372008\n",
      "Step 34, Loss: 0.6154729959116484\n",
      "Step 35, Loss: 0.6133839892131531\n",
      "Step 36, Loss: 0.6113054522257345\n",
      "Step 37, Loss: 0.6092373283602671\n",
      "Step 38, Loss: 0.6071795612554542\n",
      "Step 39, Loss: 0.6051320947787636\n",
      "Step 40, Loss: 0.6030948730273186\n",
      "Step 41, Loss: 0.6010678403287514\n",
      "Step 42, Loss: 0.5990509412420149\n",
      "Step 43, Loss: 0.5970441205581549\n",
      "Step 44, Loss: 0.5950473233010443\n",
      "Step 45, Loss: 0.5930604947280784\n",
      "Step 46, Loss: 0.5910835803308325\n",
      "Step 47, Loss: 0.5891165258356833\n",
      "Step 48, Loss: 0.587159277204392\n",
      "Step 49, Loss: 0.5852117806346532\n",
      "Step 50, Loss: 0.5832739825606077\n",
      "Step 51, Loss: 0.5813458296533203\n",
      "Step 52, Loss: 0.5794272688212234\n",
      "Step 53, Loss: 0.5775182472105276\n",
      "Step 54, Loss: 0.5756187122055977\n",
      "Step 55, Loss: 0.5737286114292978\n",
      "Step 56, Loss: 0.5718478927433032\n",
      "Step 57, Loss: 0.5699765042483814\n",
      "Step 58, Loss: 0.5681143942846417\n",
      "Step 59, Loss: 0.566261511431755\n",
      "Step 60, Loss: 0.5644178045091424\n",
      "Step 61, Loss: 0.5625832225761367\n",
      "Step 62, Loss: 0.5607577149321127\n",
      "Step 63, Loss: 0.5589412311165909\n",
      "Step 64, Loss: 0.557133720909312\n",
      "Step 65, Loss: 0.5553351343302859\n",
      "Step 66, Loss: 0.5535454216398118\n",
      "Step 67, Loss: 0.5517645333384738\n",
      "Step 68, Loss: 0.5499924201671095\n",
      "Step 69, Loss: 0.5482290331067545\n",
      "Step 70, Loss: 0.5464743233785608\n",
      "Step 71, Loss: 0.5447282424436914\n",
      "Step 72, Loss: 0.5429907420031919\n",
      "Step 73, Loss: 0.5412617739978367\n",
      "Step 74, Loss: 0.539541290607955\n",
      "Step 75, Loss: 0.5378292442532318\n",
      "Step 76, Loss: 0.5361255875924885\n",
      "Step 77, Loss: 0.5344302735234416\n",
      "Step 78, Loss: 0.5327432551824395\n",
      "Step 79, Loss: 0.53106448594418\n",
      "Step 80, Loss: 0.5293939194214069\n",
      "Step 81, Loss: 0.5277315094645862\n",
      "Step 82, Loss: 0.5260772101615647\n",
      "Step 83, Loss: 0.5244309758372071\n",
      "Step 84, Loss: 0.5227927610530175\n",
      "Step 85, Loss: 0.5211625206067406\n",
      "Step 86, Loss: 0.5195402095319457\n",
      "Step 87, Loss: 0.5179257830975944\n",
      "Step 88, Loss: 0.5163191968075903\n",
      "Step 89, Loss: 0.5147204064003121\n",
      "Step 90, Loss: 0.5131293678481325\n",
      "Step 91, Loss: 0.5115460373569178\n",
      "Step 92, Loss: 0.5099703713655164\n",
      "Step 93, Loss: 0.5084023265452283\n",
      "Step 94, Loss: 0.5068418597992637\n",
      "Step 95, Loss: 0.5052889282621836\n",
      "Step 96, Loss: 0.5037434892993299\n",
      "Step 97, Loss: 0.50220550050624\n",
      "Step 98, Loss: 0.5006749197080482\n",
      "Step 99, Loss: 0.49915170495887523\n",
      "Step 100, Loss: 0.49763581454120454\n",
      "Step 101, Loss: 0.49612720696524654\n",
      "Step 102, Loss: 0.4946258409682913\n",
      "Step 103, Loss: 0.4931316755140489\n",
      "Step 104, Loss: 0.49164466979197985\n",
      "Step 105, Loss: 0.4901647832166131\n",
      "Step 106, Loss: 0.4886919754268547\n",
      "Step 107, Loss: 0.4872262062852856\n",
      "Step 108, Loss: 0.4857674358774494\n",
      "Step 109, Loss: 0.4843156245111308\n",
      "Step 110, Loss: 0.4828707327156241\n",
      "Step 111, Loss: 0.48143272124099284\n",
      "Step 112, Loss: 0.4800015510573213\n",
      "Step 113, Loss: 0.4785771833539558\n",
      "Step 114, Loss: 0.4771595795387394\n",
      "Step 115, Loss: 0.47574870123723756\n",
      "Step 116, Loss: 0.4743445102919564\n",
      "Step 117, Loss: 0.47294696876155357\n",
      "Step 118, Loss: 0.4715560389200412\n",
      "Step 119, Loss: 0.47017168325598346\n",
      "Step 120, Loss: 0.46879386447168514\n",
      "Step 121, Loss: 0.4674225454823754\n",
      "Step 122, Loss: 0.4660576894153847\n",
      "Step 123, Loss: 0.46469925960931635\n",
      "Step 124, Loss: 0.46334721961321024\n",
      "Step 125, Loss: 0.4620015331857043\n",
      "Step 126, Loss: 0.4606621642941869\n",
      "Step 127, Loss: 0.4593290771139475\n",
      "Step 128, Loss: 0.4580022360273199\n",
      "Step 129, Loss: 0.4566816056228224\n",
      "Step 130, Loss: 0.4553671506942921\n",
      "Step 131, Loss: 0.4540588362400166\n",
      "Step 132, Loss: 0.45275662746185963\n",
      "Step 133, Loss: 0.45146048976438463\n",
      "Step 134, Loss: 0.4501703887539733\n",
      "Step 135, Loss: 0.44888629023794135\n",
      "Step 136, Loss: 0.4476081602236508\n",
      "Step 137, Loss: 0.4463359649176188\n",
      "Step 138, Loss: 0.445069670724624\n",
      "Step 139, Loss: 0.44380924424681\n",
      "Step 140, Loss: 0.4425546522827855\n",
      "Step 141, Loss: 0.44130586182672316\n",
      "Step 142, Loss: 0.44006284006745516\n",
      "Step 143, Loss: 0.43882555438756754\n",
      "Step 144, Loss: 0.4375939723624916\n",
      "Step 145, Loss: 0.43636806175959414\n",
      "Step 146, Loss: 0.43514779053726615\n",
      "Step 147, Loss: 0.43393312684400953\n",
      "Step 148, Loss: 0.43272403901752277\n",
      "Step 149, Loss: 0.4315204955837851\n",
      "Step 150, Loss: 0.43032246525614\n",
      "Step 151, Loss: 0.42912991693437746\n",
      "Step 152, Loss: 0.4279428197038159\n",
      "Step 153, Loss: 0.42676114283438227\n",
      "Step 154, Loss: 0.42558485577969307\n",
      "Step 155, Loss: 0.4244139281761342\n",
      "Step 156, Loss: 0.42324832984194016\n",
      "Step 157, Loss: 0.4220880307762744\n",
      "Step 158, Loss: 0.4209330011583075\n",
      "Step 159, Loss: 0.4197832113462979\n",
      "Step 160, Loss: 0.4186386318766708\n",
      "Step 161, Loss: 0.4174992334630982\n",
      "Step 162, Loss: 0.4163649869955798\n",
      "Step 163, Loss: 0.4152358635395229\n",
      "Step 164, Loss: 0.4141118343348248\n",
      "Step 165, Loss: 0.41299287079495456\n",
      "Step 166, Loss: 0.41187894450603574\n",
      "Step 167, Loss: 0.4107700272259306\n",
      "Step 168, Loss: 0.40966609088332506\n",
      "Step 169, Loss: 0.40856710757681414\n",
      "Step 170, Loss: 0.40747304957398967\n",
      "Step 171, Loss: 0.4063838893105284\n",
      "Step 172, Loss: 0.4052995993892818\n",
      "Step 173, Loss: 0.4042201525793672\n",
      "Step 174, Loss: 0.4031455218152603\n",
      "Step 175, Loss: 0.4020756801958899\n",
      "Step 176, Loss: 0.40101060098373353\n",
      "Step 177, Loss: 0.399950257603915\n",
      "Step 178, Loss: 0.3988946236433044\n",
      "Step 179, Loss: 0.397843672849619\n",
      "Step 180, Loss: 0.39679737913052693\n",
      "Step 181, Loss: 0.3957557165527523\n",
      "Step 182, Loss: 0.394718659341183\n",
      "Step 183, Loss: 0.39368618187797993\n",
      "Step 184, Loss: 0.3926582587016889\n",
      "Step 185, Loss: 0.39163486450635543\n",
      "Step 186, Loss: 0.3906159741406402\n",
      "Step 187, Loss: 0.38960156260693846\n",
      "Step 188, Loss: 0.38859160506050117\n",
      "Step 189, Loss: 0.3875860768085589\n",
      "Step 190, Loss: 0.3865849533094481\n",
      "Step 191, Loss: 0.38558821017174005\n",
      "Step 192, Loss: 0.3845958231533725\n",
      "Step 193, Loss: 0.383607768160784\n",
      "Step 194, Loss: 0.3826240212480508\n",
      "Step 195, Loss: 0.3816445586160269\n",
      "Step 196, Loss: 0.3806693566114866\n",
      "Step 197, Loss: 0.3796983917262702\n",
      "Step 198, Loss: 0.37873164059643216\n",
      "Step 199, Loss: 0.37776908000139314\n",
      "Step 200, Loss: 0.3768106868630939\n",
      "Step 201, Loss: 0.37585643824515275\n",
      "Step 202, Loss: 0.3749063113520264\n",
      "Step 203, Loss: 0.3739602835281737\n",
      "Step 204, Loss: 0.37301833225722175\n",
      "Step 205, Loss: 0.37208043516113665\n",
      "Step 206, Loss: 0.37114656999939577\n",
      "Step 207, Loss: 0.37021671466816514\n",
      "Step 208, Loss: 0.36929084719947824\n",
      "Step 209, Loss: 0.3683689457604193\n",
      "Step 210, Loss: 0.3674509886523091\n",
      "Step 211, Loss: 0.366536954309895\n",
      "Step 212, Loss: 0.3656268213005437\n",
      "Step 213, Loss: 0.36472056832343747\n",
      "Step 214, Loss: 0.36381817420877355\n",
      "Step 215, Loss: 0.3629196179169678\n",
      "Step 216, Loss: 0.3620248785378608\n",
      "Step 217, Loss: 0.3611339352899282\n",
      "Step 218, Loss: 0.360246767519494\n",
      "Step 219, Loss: 0.3593633546999473\n",
      "Step 220, Loss: 0.35848367643096346\n",
      "Step 221, Loss: 0.35760771243772765\n",
      "Step 222, Loss: 0.3567354425701625\n",
      "Step 223, Loss: 0.3558668468021591\n",
      "Step 224, Loss: 0.35500190523081243\n",
      "Step 225, Loss: 0.3541405980756585\n",
      "Step 226, Loss: 0.3532829056779173\n",
      "Step 227, Loss: 0.35242880849973757\n",
      "Step 228, Loss: 0.3515782871234465\n",
      "Step 229, Loss: 0.3507313222508018\n",
      "Step 230, Loss: 0.34988789470224874\n",
      "Step 231, Loss: 0.34904798541617965\n",
      "Step 232, Loss: 0.34821157544819803\n",
      "Step 233, Loss: 0.34737864597038537\n",
      "Step 234, Loss: 0.34654917827057263\n",
      "Step 235, Loss: 0.34572315375161444\n",
      "Step 236, Loss: 0.3449005539306678\n",
      "Step 237, Loss: 0.3440813604384739\n",
      "Step 238, Loss: 0.34326555501864375\n",
      "Step 239, Loss: 0.3424531195269475\n",
      "Step 240, Loss: 0.3416440359306076\n",
      "Step 241, Loss: 0.3408382863075957\n",
      "Step 242, Loss: 0.3400358528459325\n",
      "Step 243, Loss: 0.33923671784299253\n",
      "Step 244, Loss: 0.3384408637048113\n",
      "Step 245, Loss: 0.33764827294539723\n",
      "Step 246, Loss: 0.33685892818604657\n",
      "Step 247, Loss: 0.3360728121546624\n",
      "Step 248, Loss: 0.335289907685077\n",
      "Step 249, Loss: 0.3345101977163781\n",
      "Step 250, Loss: 0.3337336652922389\n",
      "Step 251, Loss: 0.3329602935602514\n",
      "Step 252, Loss: 0.3321900657712638\n",
      "Step 253, Loss: 0.33142296527872134\n",
      "Step 254, Loss: 0.3306589755380107\n",
      "Step 255, Loss: 0.32989808010580857\n",
      "Step 256, Loss: 0.3291402626394333\n",
      "Step 257, Loss: 0.32838550689620033\n",
      "Step 258, Loss: 0.32763379673278137\n",
      "Step 259, Loss: 0.32688511610456744\n",
      "Step 260, Loss: 0.32613944906503506\n",
      "Step 261, Loss: 0.3253967797651164\n",
      "Step 262, Loss: 0.32465709245257274\n",
      "Step 263, Loss: 0.3239203714713718\n",
      "Step 264, Loss: 0.32318660126106896\n",
      "Step 265, Loss: 0.32245576635619133\n",
      "Step 266, Loss: 0.32172785138562554\n",
      "Step 267, Loss: 0.32100284107201005\n",
      "Step 268, Loss: 0.3202807202311297\n",
      "Step 269, Loss: 0.3195614737713149\n",
      "Step 270, Loss: 0.31884508669284345\n",
      "Step 271, Loss: 0.31813154408734656\n",
      "Step 272, Loss: 0.3174208311372184\n",
      "Step 273, Loss: 0.31671293311502846\n",
      "Step 274, Loss: 0.3160078353829383\n",
      "Step 275, Loss: 0.3153055233921212\n",
      "Step 276, Loss: 0.3146059826821855\n",
      "Step 277, Loss: 0.31390919888060154\n",
      "Step 278, Loss: 0.31321515770213176\n",
      "Step 279, Loss: 0.31252384494826435\n",
      "Step 280, Loss: 0.3118352465066506\n",
      "Step 281, Loss: 0.3111493483505454\n",
      "Step 282, Loss: 0.31046613653825117\n",
      "Step 283, Loss: 0.30978559721256504\n",
      "Step 284, Loss: 0.30910771660023023\n",
      "Step 285, Loss: 0.3084324810113894\n",
      "Step 286, Loss: 0.3077598768390428\n",
      "Step 287, Loss: 0.3070898905585089\n",
      "Step 288, Loss: 0.30642250872688853\n",
      "Step 289, Loss: 0.30575771798253226\n",
      "Step 290, Loss: 0.3050955050445119\n",
      "Step 291, Loss: 0.3044358567120937\n",
      "Step 292, Loss: 0.30377875986421643\n",
      "Step 293, Loss: 0.3031242014589718\n",
      "Step 294, Loss: 0.3024721685330885\n",
      "Step 295, Loss: 0.3018226482014193\n",
      "Step 296, Loss: 0.30117562765643163\n",
      "Step 297, Loss: 0.3005310941677008\n",
      "Step 298, Loss: 0.29988903508140746\n",
      "Step 299, Loss: 0.299249437819837\n",
      "Step 300, Loss: 0.29861228988088323\n",
      "Step 301, Loss: 0.2979775788375542\n",
      "Step 302, Loss: 0.29734529233748236\n",
      "Step 303, Loss: 0.29671541810243646\n",
      "Step 304, Loss: 0.29608794392783794\n",
      "Step 305, Loss: 0.29546285768227926\n",
      "Step 306, Loss: 0.294840147307046\n",
      "Step 307, Loss: 0.29421980081564203\n",
      "Step 308, Loss: 0.29360180629331717\n",
      "Step 309, Loss: 0.29298615189659866\n",
      "Step 310, Loss: 0.292372825852825\n",
      "Step 311, Loss: 0.2917618164596832\n",
      "Step 312, Loss: 0.2911531120847488\n",
      "Step 313, Loss: 0.2905467011650292\n",
      "Step 314, Loss: 0.2899425722065093\n",
      "Step 315, Loss: 0.28934071378370085\n",
      "Step 316, Loss: 0.2887411145391944\n",
      "Step 317, Loss: 0.28814376318321394\n",
      "Step 318, Loss: 0.2875486484931749\n",
      "Step 319, Loss: 0.2869557593132447\n",
      "Step 320, Loss: 0.2863650845539062\n",
      "Step 321, Loss: 0.2857766131915243\n",
      "Step 322, Loss: 0.28519033426791507\n",
      "Step 323, Loss: 0.2846062368899179\n",
      "Step 324, Loss: 0.2840243102289701\n",
      "Step 325, Loss: 0.2834445435206851\n",
      "Step 326, Loss: 0.2828669260644323\n",
      "Step 327, Loss: 0.28229144722292077\n",
      "Step 328, Loss: 0.28171809642178514\n",
      "Step 329, Loss: 0.28114686314917403\n",
      "Step 330, Loss: 0.280577736955342\n",
      "Step 331, Loss: 0.2800107074522433\n",
      "Step 332, Loss: 0.2794457643131289\n",
      "Step 333, Loss: 0.27888289727214577\n",
      "Step 334, Loss: 0.27832209612393954\n",
      "Step 335, Loss: 0.27776335072325886\n",
      "Step 336, Loss: 0.277206650984563\n",
      "Step 337, Loss: 0.27665198688163223\n",
      "Step 338, Loss: 0.2760993484471798\n",
      "Step 339, Loss: 0.27554872577246814\n",
      "Step 340, Loss: 0.2750001090069258\n",
      "Step 341, Loss: 0.27445348835776834\n",
      "Step 342, Loss: 0.2739088540896213\n",
      "Step 343, Loss: 0.27336619652414534\n",
      "Step 344, Loss: 0.2728255060396645\n",
      "Step 345, Loss: 0.2722867730707964\n",
      "Step 346, Loss: 0.2717499881080856\n",
      "Step 347, Loss: 0.27121514169763833\n",
      "Step 348, Loss: 0.27068222444076107\n",
      "Step 349, Loss: 0.27015122699360056\n",
      "Step 350, Loss: 0.2696221400667864\n",
      "Step 351, Loss: 0.26909495442507636\n",
      "Step 352, Loss: 0.2685696608870037\n",
      "Step 353, Loss: 0.2680462503245272\n",
      "Step 354, Loss: 0.2675247136626837\n",
      "Step 355, Loss: 0.2670050418792421\n",
      "Step 356, Loss: 0.26648722600436076\n",
      "Step 357, Loss: 0.2659712571202468\n",
      "Step 358, Loss: 0.2654571263608173\n",
      "Step 359, Loss: 0.2649448249113636\n",
      "Step 360, Loss: 0.2644343440082171\n",
      "Step 361, Loss: 0.26392567493841773\n",
      "Step 362, Loss: 0.2634188090393848\n",
      "Step 363, Loss: 0.26291373769858983\n",
      "Step 364, Loss: 0.26241045235323146\n",
      "Step 365, Loss: 0.26190894448991286\n",
      "Step 366, Loss: 0.26140920564432135\n",
      "Step 367, Loss: 0.26091122740091016\n",
      "Step 368, Loss: 0.26041500139258184\n",
      "Step 369, Loss: 0.2599205193003747\n",
      "Step 370, Loss: 0.25942777285315083\n",
      "Step 371, Loss: 0.25893675382728637\n",
      "Step 372, Loss: 0.2584474540463637\n",
      "Step 373, Loss: 0.2579598653808663\n",
      "Step 374, Loss: 0.25747397974787484\n",
      "Step 375, Loss: 0.25698978911076614\n",
      "Step 376, Loss: 0.25650728547891366\n",
      "Step 377, Loss: 0.2560264609073905\n",
      "Step 378, Loss: 0.2555473074966737\n",
      "Step 379, Loss: 0.2550698173923515\n",
      "Step 380, Loss: 0.25459398278483153\n",
      "Step 381, Loss: 0.25411979590905226\n",
      "Step 382, Loss: 0.2536472490441951\n",
      "Step 383, Loss: 0.25317633451339955\n",
      "Step 384, Loss: 0.2527070446834796\n",
      "Step 385, Loss: 0.25223937196464236\n",
      "Step 386, Loss: 0.2517733088102087\n",
      "Step 387, Loss: 0.25130884771633555\n",
      "Step 388, Loss: 0.2508459812217401\n",
      "Step 389, Loss: 0.25038470190742657\n",
      "Step 390, Loss: 0.2499250023964133\n",
      "Step 391, Loss: 0.24946687535346393\n",
      "Step 392, Loss: 0.24901031348481809\n",
      "Step 393, Loss: 0.2485553095379256\n",
      "Step 394, Loss: 0.24810185630118212\n",
      "Step 395, Loss: 0.24764994660366577\n",
      "Step 396, Loss: 0.24719957331487677\n",
      "Step 397, Loss: 0.24675072934447814\n",
      "Step 398, Loss: 0.24630340764203823\n",
      "Step 399, Loss: 0.24585760119677513\n",
      "Step 400, Loss: 0.24541330303730302\n",
      "Step 401, Loss: 0.24497050623137998\n",
      "Step 402, Loss: 0.24452920388565735\n",
      "Step 403, Loss: 0.24408938914543163\n",
      "Step 404, Loss: 0.24365105519439695\n",
      "Step 405, Loss: 0.24321419525440008\n",
      "Step 406, Loss: 0.24277880258519682\n",
      "Step 407, Loss: 0.24234487048421044\n",
      "Step 408, Loss: 0.24191239228629072\n",
      "Step 409, Loss: 0.2414813613634758\n",
      "Step 410, Loss: 0.24105177112475537\n",
      "Step 411, Loss: 0.24062361501583485\n",
      "Step 412, Loss: 0.24019688651890214\n",
      "Step 413, Loss: 0.2397715791523954\n",
      "Step 414, Loss: 0.23934768647077206\n",
      "Step 415, Loss: 0.23892520206428067\n",
      "Step 416, Loss: 0.2385041195587329\n",
      "Step 417, Loss: 0.23808443261527806\n",
      "Step 418, Loss: 0.23766613493017857\n",
      "Step 419, Loss: 0.2372492202345875\n",
      "Step 420, Loss: 0.23683368229432727\n",
      "Step 421, Loss: 0.23641951490966995\n",
      "Step 422, Loss: 0.23600671191511907\n",
      "Step 423, Loss: 0.23559526717919302\n",
      "Step 424, Loss: 0.23518517460420982\n",
      "Step 425, Loss: 0.23477642812607336\n",
      "Step 426, Loss: 0.23436902171406132\n",
      "Step 427, Loss: 0.23396294937061413\n",
      "Step 428, Loss: 0.23355820513112582\n",
      "Step 429, Loss: 0.233154783063736\n",
      "Step 430, Loss: 0.23275267726912335\n",
      "Step 431, Loss: 0.23235188188030084\n",
      "Step 432, Loss: 0.23195239106241147\n",
      "Step 433, Loss: 0.23155419901252666\n",
      "Step 434, Loss: 0.23115729995944498\n",
      "Step 435, Loss: 0.2307616881634926\n",
      "Step 436, Loss: 0.23036735791632537\n",
      "Step 437, Loss: 0.2299743035407319\n",
      "Step 438, Loss: 0.2295825193904382\n",
      "Step 439, Loss: 0.2291919998499135\n",
      "Step 440, Loss: 0.22880273933417733\n",
      "Step 441, Loss: 0.22841473228860856\n",
      "Step 442, Loss: 0.22802797318875462\n",
      "Step 443, Loss: 0.22764245654014317\n",
      "Step 444, Loss: 0.22725817687809424\n",
      "Step 445, Loss: 0.22687512876753416\n",
      "Step 446, Loss: 0.22649330680281035\n",
      "Step 447, Loss: 0.22611270560750774\n",
      "Step 448, Loss: 0.22573331983426634\n",
      "Step 449, Loss: 0.2253551441645998\n",
      "Step 450, Loss: 0.2249781733087156\n",
      "Step 451, Loss: 0.22460240200533632\n",
      "Step 452, Loss: 0.2242278250215218\n",
      "Step 453, Loss: 0.22385443715249317\n",
      "Step 454, Loss: 0.22348223322145755\n",
      "Step 455, Loss: 0.2231112080794342\n",
      "Step 456, Loss: 0.22274135660508151\n",
      "Step 457, Loss: 0.2223726737045258\n",
      "Step 458, Loss: 0.22200515431119064\n",
      "Step 459, Loss: 0.22163879338562795\n",
      "Step 460, Loss: 0.22127358591534926\n",
      "Step 461, Loss: 0.22090952691465965\n",
      "Step 462, Loss: 0.22054661142449125\n",
      "Step 463, Loss: 0.22018483451223883\n",
      "Step 464, Loss: 0.21982419127159628\n",
      "Step 465, Loss: 0.2194646768223941\n",
      "Step 466, Loss: 0.219106286310438\n",
      "Step 467, Loss: 0.21874901490734885\n",
      "Step 468, Loss: 0.21839285781040346\n",
      "Step 469, Loss: 0.21803781024237623\n",
      "Step 470, Loss: 0.21768386745138268\n",
      "Step 471, Loss: 0.21733102471072308\n",
      "Step 472, Loss: 0.21697927731872774\n",
      "Step 473, Loss: 0.21662862059860324\n",
      "Step 474, Loss: 0.21627904989827962\n",
      "Step 475, Loss: 0.21593056059025856\n",
      "Step 476, Loss: 0.21558314807146275\n",
      "Step 477, Loss: 0.2152368077630862\n",
      "Step 478, Loss: 0.21489153511044562\n",
      "Step 479, Loss: 0.21454732558283254\n",
      "Step 480, Loss: 0.21420417467336683\n",
      "Step 481, Loss: 0.21386207789885112\n",
      "Step 482, Loss: 0.21352103079962587\n",
      "Step 483, Loss: 0.21318102893942573\n",
      "Step 484, Loss: 0.21284206790523677\n",
      "Step 485, Loss: 0.212504143307155\n",
      "Step 486, Loss: 0.21216725077824514\n",
      "Step 487, Loss: 0.21183138597440088\n",
      "Step 488, Loss: 0.21149654457420625\n",
      "Step 489, Loss: 0.21116272227879718\n",
      "Step 490, Loss: 0.2108299148117247\n",
      "Step 491, Loss: 0.2104981179188189\n",
      "Step 492, Loss: 0.2101673273680535\n",
      "Step 493, Loss: 0.2098375389494116\n",
      "Step 494, Loss: 0.2095087484747524\n",
      "Step 495, Loss: 0.2091809517776787\n",
      "Step 496, Loss: 0.20885414471340502\n",
      "Step 497, Loss: 0.20852832315862727\n",
      "Step 498, Loss: 0.20820348301139263\n",
      "Step 499, Loss: 0.20787962019097073\n",
      "Step 500, Loss: 0.20755673063772534\n",
      "Step 501, Loss: 0.20723481031298743\n",
      "Step 502, Loss: 0.2069138551989286\n",
      "Step 503, Loss: 0.20659386129843552\n",
      "Step 504, Loss: 0.2062748246349853\n",
      "Step 505, Loss: 0.20595674125252164\n",
      "Step 506, Loss: 0.20563960721533164\n",
      "Step 507, Loss: 0.20532341860792386\n",
      "Step 508, Loss: 0.20500817153490666\n",
      "Step 509, Loss: 0.20469386212086793\n",
      "Step 510, Loss: 0.20438048651025487\n",
      "Step 511, Loss: 0.20406804086725547\n",
      "Step 512, Loss: 0.20375652137568004\n",
      "Step 513, Loss: 0.20344592423884408\n",
      "Step 514, Loss: 0.20313624567945132\n",
      "Step 515, Loss: 0.2028274819394784\n",
      "Step 516, Loss: 0.20251962928005912\n",
      "Step 517, Loss: 0.202212683981371\n",
      "Step 518, Loss: 0.20190664234252087\n",
      "Step 519, Loss: 0.20160150068143298\n",
      "Step 520, Loss: 0.20129725533473625\n",
      "Step 521, Loss: 0.20099390265765343\n",
      "Step 522, Loss: 0.20069143902389044\n",
      "Step 523, Loss: 0.20038986082552662\n",
      "Step 524, Loss: 0.20008916447290545\n",
      "Step 525, Loss: 0.1997893463945266\n",
      "Step 526, Loss: 0.19949040303693807\n",
      "Step 527, Loss: 0.19919233086462906\n",
      "Step 528, Loss: 0.19889512635992435\n",
      "Step 529, Loss: 0.19859878602287828\n",
      "Step 530, Loss: 0.19830330637117016\n",
      "Step 531, Loss: 0.1980086839400002\n",
      "Step 532, Loss: 0.1977149152819861\n",
      "Step 533, Loss: 0.19742199696706017\n",
      "Step 534, Loss: 0.1971299255823675\n",
      "Step 535, Loss: 0.19683869773216447\n",
      "Step 536, Loss: 0.19654831003771786\n",
      "Step 537, Loss: 0.19625875913720528\n",
      "Step 538, Loss: 0.1959700416856154\n",
      "Step 539, Loss: 0.19568215435464922\n",
      "Step 540, Loss: 0.19539509383262235\n",
      "Step 541, Loss: 0.19510885682436716\n",
      "Step 542, Loss: 0.19482344005113628\n",
      "Step 543, Loss: 0.19453884025050633\n",
      "Step 544, Loss: 0.19425505417628247\n",
      "Step 545, Loss: 0.19397207859840346\n",
      "Step 546, Loss: 0.1936899103028474\n",
      "Step 547, Loss: 0.1934085460915381\n",
      "Step 548, Loss: 0.19312798278225202\n",
      "Step 549, Loss: 0.192848217208526\n",
      "Step 550, Loss: 0.19256924621956517\n",
      "Step 551, Loss: 0.19229106668015206\n",
      "Step 552, Loss: 0.19201367547055564\n",
      "Step 553, Loss: 0.19173706948644167\n",
      "Step 554, Loss: 0.19146124563878292\n",
      "Step 555, Loss: 0.1911862008537706\n",
      "Step 556, Loss: 0.1909119320727259\n",
      "Step 557, Loss: 0.19063843625201243\n",
      "Step 558, Loss: 0.19036571036294905\n",
      "Step 559, Loss: 0.19009375139172335\n",
      "Step 560, Loss: 0.1898225563393055\n",
      "Step 561, Loss: 0.18955212222136317\n",
      "Step 562, Loss: 0.1892824460681762\n",
      "Step 563, Loss: 0.18901352492455295\n",
      "Step 564, Loss: 0.18874535584974567\n",
      "Step 565, Loss: 0.1884779359173681\n",
      "Step 566, Loss: 0.1882112622153123\n",
      "Step 567, Loss: 0.18794533184566653\n",
      "Step 568, Loss: 0.1876801419246339\n",
      "Step 569, Loss: 0.1874156895824511\n",
      "Step 570, Loss: 0.1871519719633079\n",
      "Step 571, Loss: 0.186888986225267\n",
      "Step 572, Loss: 0.18662672954018483\n",
      "Step 573, Loss: 0.18636519909363208\n",
      "Step 574, Loss: 0.18610439208481572\n",
      "Step 575, Loss: 0.1858443057265007\n",
      "Step 576, Loss: 0.18558493724493239\n",
      "Step 577, Loss: 0.18532628387976005\n",
      "Step 578, Loss: 0.1850683428839598\n",
      "Step 579, Loss: 0.18481111152375904\n",
      "Step 580, Loss: 0.18455458707856082\n",
      "Step 581, Loss: 0.18429876684086885\n",
      "Step 582, Loss: 0.18404364811621285\n",
      "Step 583, Loss: 0.18378922822307472\n",
      "Step 584, Loss: 0.18353550449281472\n",
      "Step 585, Loss: 0.1832824742695987\n",
      "Step 586, Loss: 0.18303013491032508\n",
      "Step 587, Loss: 0.18277848378455316\n",
      "Step 588, Loss: 0.18252751827443092\n",
      "Step 589, Loss: 0.182277235774624\n",
      "Step 590, Loss: 0.18202763369224523\n",
      "Step 591, Loss: 0.18177870944678368\n",
      "Step 592, Loss: 0.18153046047003538\n",
      "Step 593, Loss: 0.1812828842060335\n",
      "Step 594, Loss: 0.1810359781109794\n",
      "Step 595, Loss: 0.18078973965317438\n",
      "Step 596, Loss: 0.18054416631295125\n",
      "Step 597, Loss: 0.1802992555826068\n",
      "Step 598, Loss: 0.18005500496633445\n",
      "Step 599, Loss: 0.1798114119801577\n",
      "Step 600, Loss: 0.1795684741518634\n",
      "Step 601, Loss: 0.17932618902093608\n",
      "Step 602, Loss: 0.17908455413849217\n",
      "Step 603, Loss: 0.17884356706721513\n",
      "Step 604, Loss: 0.17860322538129036\n",
      "Step 605, Loss: 0.17836352666634134\n",
      "Step 606, Loss: 0.17812446851936542\n",
      "Step 607, Loss: 0.17788604854867046\n",
      "Step 608, Loss: 0.17764826437381165\n",
      "Step 609, Loss: 0.177411113625529\n",
      "Step 610, Loss: 0.17717459394568483\n",
      "Step 611, Loss: 0.17693870298720213\n",
      "Step 612, Loss: 0.17670343841400282\n",
      "Step 613, Loss: 0.17646879790094672\n",
      "Step 614, Loss: 0.1762347791337708\n",
      "Step 615, Loss: 0.17600137980902894\n",
      "Step 616, Loss: 0.17576859763403185\n",
      "Step 617, Loss: 0.17553643032678745\n",
      "Step 618, Loss: 0.17530487561594194\n",
      "Step 619, Loss: 0.17507393124072046\n",
      "Step 620, Loss: 0.1748435949508692\n",
      "Step 621, Loss: 0.17461386450659674\n",
      "Step 622, Loss: 0.17438473767851675\n",
      "Step 623, Loss: 0.17415621224759043\n",
      "Step 624, Loss: 0.17392828600506952\n",
      "Step 625, Loss: 0.1737009567524396\n",
      "Step 626, Loss: 0.1734742223013638\n",
      "Step 627, Loss: 0.17324808047362703\n",
      "Step 628, Loss: 0.1730225291010801\n",
      "Step 629, Loss: 0.17279756602558471\n",
      "Step 630, Loss: 0.1725731890989583\n",
      "Step 631, Loss: 0.17234939618291978\n",
      "Step 632, Loss: 0.17212618514903513\n",
      "Step 633, Loss: 0.17190355387866346\n",
      "Step 634, Loss: 0.17168150026290374\n",
      "Step 635, Loss: 0.1714600222025412\n",
      "Step 636, Loss: 0.17123911760799476\n",
      "Step 637, Loss: 0.17101878439926435\n",
      "Step 638, Loss: 0.17079902050587872\n",
      "Step 639, Loss: 0.17057982386684356\n",
      "Step 640, Loss: 0.17036119243058984\n",
      "Step 641, Loss: 0.1701431241549226\n",
      "Step 642, Loss: 0.16992561700697004\n",
      "Step 643, Loss: 0.16970866896313289\n",
      "Step 644, Loss: 0.16949227800903402\n",
      "Step 645, Loss: 0.16927644213946855\n",
      "Step 646, Loss: 0.16906115935835417\n",
      "Step 647, Loss: 0.16884642767868158\n",
      "Step 648, Loss: 0.1686322451224656\n",
      "Step 649, Loss: 0.16841860972069633\n",
      "Step 650, Loss: 0.1682055195132907\n",
      "Step 651, Loss: 0.1679929725490443\n",
      "Step 652, Loss: 0.16778096688558342\n",
      "Step 653, Loss: 0.1675695005893176\n",
      "Step 654, Loss: 0.16735857173539223\n",
      "Step 655, Loss: 0.16714817840764162\n",
      "Step 656, Loss: 0.16693831869854217\n",
      "Step 657, Loss: 0.16672899070916625\n",
      "Step 658, Loss: 0.16652019254913575\n",
      "Step 659, Loss: 0.1663119223365762\n",
      "Step 660, Loss: 0.1661041781980716\n",
      "Step 661, Loss: 0.16589695826861875\n",
      "Step 662, Loss: 0.16569026069158224\n",
      "Step 663, Loss: 0.16548408361865\n",
      "Step 664, Loss: 0.1652784252097885\n",
      "Step 665, Loss: 0.1650732836331989\n",
      "Step 666, Loss: 0.16486865706527265\n",
      "Step 667, Loss: 0.16466454369054837\n",
      "Step 668, Loss: 0.16446094170166808\n",
      "Step 669, Loss: 0.16425784929933424\n",
      "Step 670, Loss: 0.16405526469226686\n",
      "Step 671, Loss: 0.1638531860971608\n",
      "Step 672, Loss: 0.16365161173864365\n",
      "Step 673, Loss: 0.16345053984923338\n",
      "Step 674, Loss: 0.1632499686692967\n",
      "Step 675, Loss: 0.16304989644700743\n",
      "Step 676, Loss: 0.16285032143830513\n",
      "Step 677, Loss: 0.16265124190685407\n",
      "Step 678, Loss: 0.16245265612400236\n",
      "Step 679, Loss: 0.16225456236874153\n",
      "Step 680, Loss: 0.16205695892766606\n",
      "Step 681, Loss: 0.16185984409493315\n",
      "Step 682, Loss: 0.16166321617222315\n",
      "Step 683, Loss: 0.16146707346869987\n",
      "Step 684, Loss: 0.1612714143009712\n",
      "Step 685, Loss: 0.1610762369930498\n",
      "Step 686, Loss: 0.16088153987631462\n",
      "Step 687, Loss: 0.1606873212894718\n",
      "Step 688, Loss: 0.16049357957851654\n",
      "Step 689, Loss: 0.16030031309669476\n",
      "Step 690, Loss: 0.1601075202044652\n",
      "Step 691, Loss: 0.15991519926946166\n",
      "Step 692, Loss: 0.15972334866645546\n",
      "Step 693, Loss: 0.1595319667773183\n",
      "Step 694, Loss: 0.15934105199098486\n",
      "Step 695, Loss: 0.15915060270341644\n",
      "Step 696, Loss: 0.1589606173175639\n",
      "Step 697, Loss: 0.15877109424333155\n",
      "Step 698, Loss: 0.15858203189754078\n",
      "Step 699, Loss: 0.15839342870389428\n",
      "Step 700, Loss: 0.15820528309294002\n",
      "Step 701, Loss: 0.158017593502036\n",
      "Step 702, Loss: 0.15783035837531476\n",
      "Step 703, Loss: 0.15764357616364827\n",
      "Step 704, Loss: 0.15745724532461305\n",
      "Step 705, Loss: 0.15727136432245556\n",
      "Step 706, Loss: 0.1570859316280575\n",
      "Step 707, Loss: 0.15690094571890176\n",
      "Step 708, Loss: 0.156716405079038\n",
      "Step 709, Loss: 0.15653230819904923\n",
      "Step 710, Loss: 0.1563486535760177\n",
      "Step 711, Loss: 0.15616543971349173\n",
      "Step 712, Loss: 0.15598266512145212\n",
      "Step 713, Loss: 0.1558003283162794\n",
      "Step 714, Loss: 0.1556184278207207\n",
      "Step 715, Loss: 0.15543696216385708\n",
      "Step 716, Loss: 0.15525592988107118\n",
      "Step 717, Loss: 0.15507532951401465\n",
      "Step 718, Loss: 0.15489515961057632\n",
      "Step 719, Loss: 0.15471541872485006\n",
      "Step 720, Loss: 0.15453610541710305\n",
      "Step 721, Loss: 0.15435721825374438\n",
      "Step 722, Loss: 0.15417875580729345\n",
      "Step 723, Loss: 0.15400071665634898\n",
      "Step 724, Loss: 0.15382309938555794\n",
      "Step 725, Loss: 0.15364590258558455\n",
      "Step 726, Loss: 0.15346912485308006\n",
      "Step 727, Loss: 0.1532927647906518\n",
      "Step 728, Loss: 0.15311682100683327\n",
      "Step 729, Loss: 0.15294129211605378\n",
      "Step 730, Loss: 0.15276617673860873\n",
      "Step 731, Loss: 0.15259147350062968\n",
      "Step 732, Loss: 0.15241718103405485\n",
      "Step 733, Loss: 0.15224329797659966\n",
      "Step 734, Loss: 0.15206982297172764\n",
      "Step 735, Loss: 0.15189675466862115\n",
      "Step 736, Loss: 0.15172409172215262\n",
      "Step 737, Loss: 0.1515518327928558\n",
      "Step 738, Loss: 0.1513799765468972\n",
      "Step 739, Loss: 0.15120852165604753\n",
      "Step 740, Loss: 0.15103746679765384\n",
      "Step 741, Loss: 0.15086681065461105\n",
      "Step 742, Loss: 0.1506965519153343\n",
      "Step 743, Loss: 0.15052668927373106\n",
      "Step 744, Loss: 0.1503572214291737\n",
      "Step 745, Loss: 0.1501881470864719\n",
      "Step 746, Loss: 0.15001946495584556\n",
      "Step 747, Loss: 0.1498511737528975\n",
      "Step 748, Loss: 0.14968327219858663\n",
      "Step 749, Loss: 0.14951575901920117\n",
      "Step 750, Loss: 0.14934863294633188\n",
      "Step 751, Loss: 0.14918189271684587\n",
      "Step 752, Loss: 0.14901553707285978\n",
      "Step 753, Loss: 0.1488495647617141\n",
      "Step 754, Loss: 0.14868397453594678\n",
      "Step 755, Loss: 0.14851876515326762\n",
      "Step 756, Loss: 0.14835393537653224\n",
      "Step 757, Loss: 0.14818948397371676\n",
      "Step 758, Loss: 0.14802540971789224\n",
      "Step 759, Loss: 0.14786171138719936\n",
      "Step 760, Loss: 0.14769838776482336\n",
      "Step 761, Loss: 0.14753543763896892\n",
      "Step 762, Loss: 0.14737285980283546\n",
      "Step 763, Loss: 0.14721065305459224\n",
      "Step 764, Loss: 0.14704881619735397\n",
      "Step 765, Loss: 0.14688734803915607\n",
      "Step 766, Loss: 0.14672624739293083\n",
      "Step 767, Loss: 0.1465655130764828\n",
      "Step 768, Loss: 0.14640514391246504\n",
      "Step 769, Loss: 0.14624513872835512\n",
      "Step 770, Loss: 0.14608549635643148\n",
      "Step 771, Loss: 0.14592621563374958\n",
      "Step 772, Loss: 0.14576729540211875\n",
      "Step 773, Loss: 0.14560873450807857\n",
      "Step 774, Loss: 0.1454505318028758\n",
      "Step 775, Loss: 0.14529268614244115\n",
      "Step 776, Loss: 0.14513519638736658\n",
      "Step 777, Loss: 0.14497806140288227\n",
      "Step 778, Loss: 0.14482128005883393\n",
      "Step 779, Loss: 0.14466485122966039\n",
      "Step 780, Loss: 0.1445087737943709\n",
      "Step 781, Loss: 0.14435304663652318\n",
      "Step 782, Loss: 0.14419766864420086\n",
      "Step 783, Loss: 0.14404263870999168\n",
      "Step 784, Loss: 0.14388795573096547\n",
      "Step 785, Loss: 0.1437336186086523\n",
      "Step 786, Loss: 0.14357962624902088\n",
      "Step 787, Loss: 0.14342597756245687\n",
      "Step 788, Loss: 0.1432726714637415\n",
      "Step 789, Loss: 0.14311970687203032\n",
      "Step 790, Loss: 0.14296708271083192\n",
      "Step 791, Loss: 0.1428147979079867\n",
      "Step 792, Loss: 0.1426628513956462\n",
      "Step 793, Loss: 0.142511242110252\n",
      "Step 794, Loss: 0.14235996899251513\n",
      "Step 795, Loss: 0.14220903098739535\n",
      "Step 796, Loss: 0.14205842704408073\n",
      "Step 797, Loss: 0.14190815611596716\n",
      "Step 798, Loss: 0.14175821716063822\n",
      "Step 799, Loss: 0.14160860913984485\n",
      "Step 800, Loss: 0.14145933101948543\n",
      "Step 801, Loss: 0.14131038176958574\n",
      "Step 802, Loss: 0.14116176036427924\n",
      "Step 803, Loss: 0.14101346578178725\n",
      "Step 804, Loss: 0.14086549700439946\n",
      "Step 805, Loss: 0.14071785301845427\n",
      "Step 806, Loss: 0.14057053281431953\n",
      "Step 807, Loss: 0.14042353538637317\n",
      "Step 808, Loss: 0.14027685973298415\n",
      "Step 809, Loss: 0.14013050485649323\n",
      "Step 810, Loss: 0.1399844697631941\n",
      "Step 811, Loss: 0.13983875346331445\n",
      "Step 812, Loss: 0.1396933549709974\n",
      "Step 813, Loss: 0.1395482733042826\n",
      "Step 814, Loss: 0.13940350748508773\n",
      "Step 815, Loss: 0.13925905653919032\n",
      "Step 816, Loss: 0.13911491949620897\n",
      "Step 817, Loss: 0.13897109538958546\n",
      "Step 818, Loss: 0.13882758325656647\n",
      "Step 819, Loss: 0.13868438213818543\n",
      "Step 820, Loss: 0.13854149107924488\n",
      "Step 821, Loss: 0.1383989091282983\n",
      "Step 822, Loss: 0.13825663533763247\n",
      "Step 823, Loss: 0.13811466876324988\n",
      "Step 824, Loss: 0.1379730084648512\n",
      "Step 825, Loss: 0.1378316535058176\n",
      "Step 826, Loss: 0.13769060295319374\n",
      "Step 827, Loss: 0.1375498558776701\n",
      "Step 828, Loss: 0.13740941135356619\n",
      "Step 829, Loss: 0.13726926845881304\n",
      "Step 830, Loss: 0.1371294262749368\n",
      "Step 831, Loss: 0.13698988388704122\n",
      "Step 832, Loss: 0.13685064038379124\n",
      "Step 833, Loss: 0.13671169485739618\n",
      "Step 834, Loss: 0.13657304640359313\n",
      "Step 835, Loss: 0.1364346941216303\n",
      "Step 836, Loss: 0.13629663711425086\n",
      "Step 837, Loss: 0.13615887448767625\n",
      "Step 838, Loss: 0.13602140535159013\n",
      "Step 839, Loss: 0.13588422881912215\n",
      "Step 840, Loss: 0.13574734400683192\n",
      "Step 841, Loss: 0.1356107500346929\n",
      "Step 842, Loss: 0.1354744460260765\n",
      "Step 843, Loss: 0.13533843110773652\n",
      "Step 844, Loss: 0.13520270440979293\n",
      "Step 845, Loss: 0.13506726506571662\n",
      "Step 846, Loss: 0.13493211221231363\n",
      "Step 847, Loss: 0.13479724498970977\n",
      "Step 848, Loss: 0.1346626625413351\n",
      "Step 849, Loss: 0.1345283640139087\n",
      "Step 850, Loss: 0.13439434855742338\n",
      "Step 851, Loss: 0.13426061532513062\n",
      "Step 852, Loss: 0.13412716347352532\n",
      "Step 853, Loss: 0.13399399216233093\n",
      "Step 854, Loss: 0.1338611005544846\n",
      "Step 855, Loss: 0.13372848781612212\n",
      "Step 856, Loss: 0.1335961531165634\n",
      "Step 857, Loss: 0.1334640956282977\n",
      "Step 858, Loss: 0.13333231452696892\n",
      "Step 859, Loss: 0.13320080899136136\n",
      "Step 860, Loss: 0.13306957820338497\n",
      "Step 861, Loss: 0.13293862134806114\n",
      "Step 862, Loss: 0.13280793761350854\n",
      "Step 863, Loss: 0.1326775261909286\n",
      "Step 864, Loss: 0.13254738627459164\n",
      "Step 865, Loss: 0.1324175170618227\n",
      "Step 866, Loss: 0.13228791775298748\n",
      "Step 867, Loss: 0.1321585875514787\n",
      "Step 868, Loss: 0.13202952566370185\n",
      "Step 869, Loss: 0.13190073129906188\n",
      "Step 870, Loss: 0.13177220366994905\n",
      "Step 871, Loss: 0.13164394199172577\n",
      "Step 872, Loss: 0.1315159454827127\n",
      "Step 873, Loss: 0.1313882133641754\n",
      "Step 874, Loss: 0.13126074486031103\n",
      "Step 875, Loss: 0.13113353919823484\n",
      "Step 876, Loss: 0.131006595607967\n",
      "Step 877, Loss: 0.1308799133224195\n",
      "Step 878, Loss: 0.1307534915773827\n",
      "Step 879, Loss: 0.13062732961151277\n",
      "Step 880, Loss: 0.13050142666631823\n",
      "Step 881, Loss: 0.13037578198614738\n",
      "Step 882, Loss: 0.13025039481817527\n",
      "Step 883, Loss: 0.130125264412391\n",
      "Step 884, Loss: 0.13000039002158487\n",
      "Step 885, Loss: 0.12987577090133598\n",
      "Step 886, Loss: 0.12975140630999937\n",
      "Step 887, Loss: 0.12962729550869384\n",
      "Step 888, Loss: 0.12950343776128906\n",
      "Step 889, Loss: 0.12937983233439365\n",
      "Step 890, Loss: 0.12925647849734254\n",
      "Step 891, Loss: 0.12913337552218487\n",
      "Step 892, Loss: 0.12901052268367175\n",
      "Step 893, Loss: 0.12888791925924403\n",
      "Step 894, Loss: 0.12876556452902047\n",
      "Step 895, Loss: 0.12864345777578565\n",
      "Step 896, Loss: 0.1285215982849779\n",
      "Step 897, Loss: 0.12839998534467756\n",
      "Step 898, Loss: 0.12827861824559514\n",
      "Step 899, Loss: 0.12815749628105955\n",
      "Step 900, Loss: 0.12803661874700642\n",
      "Step 901, Loss: 0.1279159849419665\n",
      "Step 902, Loss: 0.127795594167054\n",
      "Step 903, Loss: 0.12767544572595516\n",
      "Step 904, Loss: 0.12755553892491686\n",
      "Step 905, Loss: 0.12743587307273507\n",
      "Step 906, Loss: 0.12731644748074358\n",
      "Step 907, Loss: 0.12719726146280286\n",
      "Step 908, Loss: 0.1270783143352886\n",
      "Step 909, Loss: 0.12695960541708076\n",
      "Step 910, Loss: 0.12684113402955235\n",
      "Step 911, Loss: 0.12672289949655852\n",
      "Step 912, Loss: 0.12660490114442538\n",
      "Step 913, Loss: 0.12648713830193933\n",
      "Step 914, Loss: 0.12636961030033586\n",
      "Step 915, Loss: 0.12625231647328905\n",
      "Step 916, Loss: 0.1261352561569006\n",
      "Step 917, Loss: 0.12601842868968927\n",
      "Step 918, Loss: 0.12590183341258007\n",
      "Step 919, Loss: 0.12578546966889387\n",
      "Step 920, Loss: 0.12566933680433653\n",
      "Step 921, Loss: 0.12555343416698886\n",
      "Step 922, Loss: 0.12543776110729585\n",
      "Step 923, Loss: 0.12532231697805643\n",
      "Step 924, Loss: 0.125207101134413\n",
      "Step 925, Loss: 0.12509211293384134\n",
      "Step 926, Loss: 0.12497735173614032\n",
      "Step 927, Loss: 0.12486281690342169\n",
      "Step 928, Loss: 0.12474850780010004\n",
      "Step 929, Loss: 0.12463442379288256\n",
      "Step 930, Loss: 0.12452056425075927\n",
      "Step 931, Loss: 0.12440692854499295\n",
      "Step 932, Loss: 0.12429351604910907\n",
      "Step 933, Loss: 0.12418032613888624\n",
      "Step 934, Loss: 0.1240673581923461\n",
      "Step 935, Loss: 0.12395461158974372\n",
      "Step 936, Loss: 0.12384208571355788\n",
      "Step 937, Loss: 0.12372977994848135\n",
      "Step 938, Loss: 0.12361769368141136\n",
      "Step 939, Loss: 0.12350582630143986\n",
      "Step 940, Loss: 0.12339417719984418\n",
      "Step 941, Loss: 0.1232827457700775\n",
      "Step 942, Loss: 0.12317153140775944\n",
      "Step 943, Loss: 0.12306053351066659\n",
      "Step 944, Loss: 0.12294975147872338\n",
      "Step 945, Loss: 0.1228391847139926\n",
      "Step 946, Loss: 0.12272883262066625\n",
      "Step 947, Loss: 0.12261869460505637\n",
      "Step 948, Loss: 0.12250877007558586\n",
      "Step 949, Loss: 0.12239905844277948\n",
      "Step 950, Loss: 0.1222895591192546\n",
      "Step 951, Loss: 0.12218027151971239\n",
      "Step 952, Loss: 0.1220711950609288\n",
      "Step 953, Loss: 0.1219623291617457\n",
      "Step 954, Loss: 0.1218536732430617\n",
      "Step 955, Loss: 0.12174522672782391\n",
      "Step 956, Loss: 0.12163698904101856\n",
      "Step 957, Loss: 0.12152895960966266\n",
      "Step 958, Loss: 0.12142113786279513\n",
      "Step 959, Loss: 0.12131352323146827\n",
      "Step 960, Loss: 0.12120611514873893\n",
      "Step 961, Loss: 0.12109891304966024\n",
      "Step 962, Loss: 0.12099191637127284\n",
      "Step 963, Loss: 0.12088512455259659\n",
      "Step 964, Loss: 0.12077853703462196\n",
      "Step 965, Loss: 0.12067215326030184\n",
      "Step 966, Loss: 0.1205659726745429\n",
      "Step 967, Loss: 0.1204599947241976\n",
      "Step 968, Loss: 0.12035421885805576\n",
      "Step 969, Loss: 0.12024864452683628\n",
      "Step 970, Loss: 0.12014327118317905\n",
      "Step 971, Loss: 0.12003809828163674\n",
      "Step 972, Loss: 0.1199331252786667\n",
      "Step 973, Loss: 0.11982835163262308\n",
      "Step 974, Loss: 0.11972377680374839\n",
      "Step 975, Loss: 0.11961940025416591\n",
      "Step 976, Loss: 0.11951522144787158\n",
      "Step 977, Loss: 0.11941123985072596\n",
      "Step 978, Loss: 0.11930745493044677\n",
      "Step 979, Loss: 0.11920386615660057\n",
      "Step 980, Loss: 0.1191004730005952\n",
      "Step 981, Loss: 0.11899727493567211\n",
      "Step 982, Loss: 0.11889427143689847\n",
      "Step 983, Loss: 0.11879146198115965\n",
      "Step 984, Loss: 0.11868884604715138\n",
      "Step 985, Loss: 0.11858642311537239\n",
      "Step 986, Loss: 0.11848419266811666\n",
      "Step 987, Loss: 0.11838215418946589\n",
      "Step 988, Loss: 0.11828030716528218\n",
      "Step 989, Loss: 0.11817865108320041\n",
      "Step 990, Loss: 0.11807718543262087\n",
      "Step 991, Loss: 0.11797590970470186\n",
      "Step 992, Loss: 0.11787482339235243\n",
      "Step 993, Loss: 0.11777392599022499\n",
      "Step 994, Loss: 0.11767321699470798\n",
      "Step 995, Loss: 0.11757269590391876\n",
      "Step 996, Loss: 0.11747236221769636\n",
      "Step 997, Loss: 0.11737221543759428\n",
      "Step 998, Loss: 0.1172722550668734\n",
      "Step 999, Loss: 0.11717248061049478\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression model\n",
    "theta = logistic_regression(X_train, y_train, num_iterations=1000)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = sigmoid(np.dot(X_test, theta)) > 0.5\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T23:15:06.606416Z",
     "start_time": "2024-04-03T23:15:06.564399Z"
    }
   },
   "execution_count": 6
  }
 ]
}
